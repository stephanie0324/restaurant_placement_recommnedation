{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a4c0bd",
   "metadata": {},
   "source": [
    "# Pointwise\n",
    "* predict the relevance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55501c4",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28aa43a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:10:37.759665Z",
     "start_time": "2023-04-27T06:10:37.096701Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import itertools\n",
    "\n",
    "# models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4eb9d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:10:41.038507Z",
     "start_time": "2023-04-27T06:10:41.032578Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ed385f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:10:41.655184Z",
     "start_time": "2023-04-27T06:10:41.623865Z"
    }
   },
   "outputs": [],
   "source": [
    "# 導入資料\n",
    "train_df = pd.read_pickle('/home/adam/Steph_C/my_thesis/data/Train_by_postoal_code_without_review_pointwise_v3_3.pkl')\n",
    "test_df = pd.read_pickle('/home/adam/Steph_C/my_thesis/data/Test_by_postoal_code_without_review_pointwise_v3_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45a252a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:10:42.357185Z",
     "start_time": "2023-04-27T06:10:42.343629Z"
    }
   },
   "outputs": [],
   "source": [
    "ori_train_df = train_df.reset_index(drop=True)\n",
    "ori_test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee55fcf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:10:43.151211Z",
     "start_time": "2023-04-27T06:10:43.141312Z"
    }
   },
   "outputs": [],
   "source": [
    "# create pairwise datasets\n",
    "\n",
    "def pairwise_transform(df):\n",
    "    \n",
    "    COL_NAME = ['name','loc_a','loc_b','density', 'entropy',\\\n",
    "                'competitiveness','area_pop', 'accessibility',\\\n",
    "                'complementary','relevance','pair_importance']\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=COL_NAME)\n",
    "    \n",
    "    for res in Counter(df.name):\n",
    "        new_row = {}\n",
    "        tmp = df[df.name==res]\n",
    "        loc_a_l = []\n",
    "        loc_b_l = []\n",
    "        comb_list = list(itertools.combinations(list(tmp.postal_code),2))\n",
    "        \n",
    "        for sets in comb_list:  #[('46142', '46250'), ('46142', '19341'), ('46142', '46123')]\n",
    "            rel_a = list(tmp.loc[tmp.postal_code==sets[0]].relevance)[0]\n",
    "            rel_b = list(tmp.loc[tmp.postal_code==sets[1]].relevance)[0]\n",
    "            \n",
    "            if rel_a != rel_b and sets[0] not in loc_a_l and sets[1] not in loc_b_l:\n",
    "                loc_a_l.append(sets[0])\n",
    "                loc_b_l.append(sets[1])\n",
    "                new_row['name'] = res\n",
    "                new_row['loc_a'] = list(tmp.loc[tmp.postal_code==sets[0]].postal_code)[0]\n",
    "                new_row['loc_b'] = list(tmp.loc[tmp.postal_code==sets[1]].postal_code)[0]\n",
    "                new_row['density'] = list(tmp.loc[tmp.postal_code==sets[0]].density)[0]-list(tmp.loc[tmp.postal_code==sets[1]].density)[0]\n",
    "                new_row['entropy'] = list(tmp.loc[tmp.postal_code==sets[0]].entropy)[0]-list(tmp.loc[tmp.postal_code==sets[1]].entropy)[0]\n",
    "                new_row['competitiveness'] = list(tmp.loc[tmp.postal_code==sets[0]].competitiveness)[0]-list(tmp.loc[tmp.postal_code==sets[1]].competitiveness)[0]\n",
    "                new_row['area_pop'] = list(tmp.loc[tmp.postal_code==sets[0]].area_pop)[0]-list(tmp.loc[tmp.postal_code==sets[1]].area_pop)[0]\n",
    "                new_row['accessibility'] = list(tmp.loc[tmp.postal_code==sets[0]].accessibility)[0]-list(tmp.loc[tmp.postal_code==sets[1]].accessibility)[0]\n",
    "                new_row['complementary'] = list(tmp.loc[tmp.postal_code==sets[0]].complementary)[0]-list(tmp.loc[tmp.postal_code==sets[1]].complementary)[0]\n",
    "                new_row['relevance'] = int(rel_a >rel_b )\n",
    "                new_row['pair_importance'] = list(tmp.loc[tmp.postal_code==sets[0]].relevance)[0]+list(tmp.loc[tmp.postal_code==sets[1]].relevance)[0]\n",
    "            new_df = new_df.append(new_row,ignore_index=True)  \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5577afc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:13:09.143397Z",
     "start_time": "2023-04-27T06:10:43.878618Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pairwise_transform(ori_train_df)\n",
    "test_df = pairwise_transform(ori_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b481dedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:14:33.963487Z",
     "start_time": "2023-04-27T06:14:33.940845Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates().reset_index(drop = True)\n",
    "test_df = test_df.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2690623c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:14:34.622467Z",
     "start_time": "2023-04-27T06:14:34.616239Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1 , random_state = RANDOM_STATE).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1 , random_state = RANDOM_STATE).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b40d61c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:14:35.470995Z",
     "start_time": "2023-04-27T06:14:35.462747Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in ['density', 'entropy', 'competitiveness','area_pop', 'accessibility','complementary','relevance']:\n",
    "    train_df[i] = train_df[i].astype('float')\n",
    "    test_df[i] = test_df[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ef8bbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:14:36.313724Z",
     "start_time": "2023-04-27T06:14:36.306964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(train_df.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb74576d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:14:36.855336Z",
     "start_time": "2023-04-27T06:14:36.849611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1136, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3701b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T06:14:37.589363Z",
     "start_time": "2023-04-27T06:14:37.584164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8860146c",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac1e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T15:33:17.796982Z",
     "start_time": "2023-04-26T15:33:17.789518Z"
    }
   },
   "outputs": [],
   "source": [
    "def _precision(predictions , actuals, k = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the precision at k\n",
    "    \n",
    "    Returns: a list of precisions\n",
    "    \"\"\"\n",
    "    \n",
    "    precisions =[]\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        \n",
    "        prediction = predictions[i]\n",
    "\n",
    "        if  k != None:\n",
    "            prediction =  predictions[i][:k]\n",
    "        \n",
    "        score = 0\n",
    "        for j in prediction:\n",
    "            if j in actuals[i]:\n",
    "                score+=1\n",
    "        if len(prediction) != 0:\n",
    "            precisions.append(score/len(prediction))\n",
    "        else:\n",
    "            precisions.append(0)\n",
    "    return precisions\n",
    "    \n",
    "\n",
    "def _recall(predictions , actuals, k = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the precision at k\n",
    "    \n",
    "    Returns: a list of recalls\n",
    "    \"\"\"\n",
    "    recalls =[]\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        \n",
    "        prediction =  predictions[i]\n",
    "        \n",
    "        if  k != None:\n",
    "            prediction =  predictions[i][:k]\n",
    "        \n",
    "        score = 0\n",
    "        for j in range(len(prediction)):\n",
    "            if prediction[j] in actuals[i]:\n",
    "                score+=1\n",
    "        recalls.append(score/len(actuals[i]))\n",
    "    \n",
    "    return recalls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba757ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T15:33:18.167842Z",
     "start_time": "2023-04-26T15:33:18.156722Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_mrr(predictions, actuals):\n",
    "    \"\"\"\n",
    "    Calculate the mean reciprocal rank (MRR) for a set of predictions and actual values.\n",
    "    \n",
    "    Parameters:\n",
    "    predictions (list of lists): A list of predicted rankings sorted by probability.\n",
    "    actual (list of lists): A list of actual rankings sorted by relevance.\n",
    "    \n",
    "    Returns:    \n",
    "    float: A list of MRR scores.\n",
    "    \"\"\"\n",
    "    mrr_list = []\n",
    "    for i in range(len(predictions)):\n",
    "        reciprocal_rank = 0\n",
    "        if actuals[i][0] in predictions[i]:\n",
    "            reciprocal_rank = 1/ (predictions[i].index(actuals[i][0]) + 1)\n",
    "        mrr_list.append(reciprocal_rank)\n",
    "    return mrr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a4af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T15:33:18.548259Z",
     "start_time": "2023-04-26T15:33:18.542213Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_map( predictions , actuals, k=None):\n",
    "    \"\"\"\n",
    "    Calculate the mean average precision (MAP) for a set of queries.\n",
    "\n",
    "    Parameters:\n",
    "    actual (list of sets or lists): A list of sets or lists of the actual relevant items for each query.\n",
    "    predicted (list of lists): A list of lists of predicted items for each query.\n",
    "    k (int): The maximum number of predicted items to consider for each query.\n",
    "\n",
    "    Returns:\n",
    "    float: A list of MAP scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    map_list = []\n",
    "    \n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        \n",
    "        ap_list = []\n",
    "        hit = 0 \n",
    "        cnt = 0 \n",
    "        \n",
    "        prediction =  predictions[i]\n",
    "        \n",
    "        if k != None:\n",
    "            prediction =  predictions[i][:k]\n",
    "        \n",
    "        \n",
    "        for j in prediction:\n",
    "            if j in actuals[i]:\n",
    "                hit+=1\n",
    "                cnt+=1\n",
    "                ap_list.append(hit/cnt)\n",
    "            else:\n",
    "                cnt+=1\n",
    "        if len(ap_list) != 0:\n",
    "            map_list.append(np.mean(ap_list))\n",
    "        else:\n",
    "            map_list.append(0)\n",
    "    \n",
    "    return map_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7ce0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T15:33:18.966255Z",
     "start_time": "2023-04-26T15:33:18.947638Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_dcg_ndcg( predictions , actuals, rel ,k=None):\n",
    "    \"\"\"\n",
    "    Calculate the DCG@k , NDCG@k for a set of queries.\n",
    "\n",
    "    Parameters:\n",
    "    actual (list of sets or lists): A list of sets or lists of the actual relevant items for each query.\n",
    "    predicted (list of lists): A list of lists of predicted items for each query.\n",
    "    k (int): The maximum number of predicted items to consider for each query.\n",
    "\n",
    "    Returns:\n",
    "    float: A list of DCG , NDCG scores.\n",
    "    \"\"\"\n",
    "    dcg_list = []\n",
    "    ndcg_list = []\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        dcg =0\n",
    "        idcg =0\n",
    "        \n",
    "        prediction = predictions[i]\n",
    "        \n",
    "        if k != None:\n",
    "            prediction = predictions[i][:k]\n",
    "        \n",
    "        for j in range(len(actuals[i])):\n",
    "            if actuals[i][j] in prediction:\n",
    "                rank = prediction.index(actuals[i][j]) + 1\n",
    "                dcg += np.divide(float(rel[i][j]),np.log2(rank+1))\n",
    "            idcg += np.divide(float(rel[i][j]),np.log2((j+1)+1))\n",
    "        dcg_list.append(dcg)\n",
    "        if np.divide(dcg,idcg) > 1:\n",
    "            print(rel[i], prediction,actuals[i]  )\n",
    "            print(i,dcg,idcg  , 'Wrong !!!')\n",
    "        ndcg_list.append(np.divide(dcg,idcg))\n",
    "        \n",
    "    return dcg_list , ndcg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df34a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T15:33:19.432372Z",
     "start_time": "2023-04-26T15:33:19.424675Z"
    }
   },
   "outputs": [],
   "source": [
    "# create list of list for query ranking\n",
    "\n",
    "def get_ranking_list(df):\n",
    "    \n",
    "    ranked_list = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        loc_a = df.loc_a[i]\n",
    "        loc_b = df.loc_b[i]\n",
    "\n",
    "        if df.predictions[i]==1: # loc_a > loc_b\n",
    "            if loc_a in ranked_list:\n",
    "                ranked_list.append(loc_b)\n",
    "            elif loc_b in ranked_list:\n",
    "                ranked_list.insert(loc_a,ranked_list.index(loc_b))\n",
    "            else:\n",
    "                ranked_list.append(loc_a)\n",
    "                ranked_list.append(loc_b)\n",
    "        else:                     # loc_b > loc_a\n",
    "            if loc_a in ranked_list:\n",
    "                ranked_list.insert(loc_b,ranked_list.index(loc_a))\n",
    "            elif loc_b in ranked_list:\n",
    "                ranked_list.append(loc_a)\n",
    "            else:\n",
    "                ranked_list.append(loc_b)\n",
    "                ranked_list.append(loc_a)\n",
    "\n",
    "    return ranked_list\n",
    "\n",
    "\n",
    "def get_ranking_pair(df,ori_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Turn the probability array into a list of lists for calculation.\n",
    "    \n",
    "    Parameters:\n",
    "    df(DataFrame): the test dataframe\n",
    "    \n",
    "    Returns:\n",
    "    prediction (list of lists): A list of predicted rankings for each query.\n",
    "    actual (list of lists): A list of actual rankings for each query.\n",
    "    \"\"\"\n",
    " \n",
    "    pred_list = []\n",
    "    pred_rel = []\n",
    "    true_list = []\n",
    "    \n",
    "    \n",
    "    for res in Counter(df.name):\n",
    "        \n",
    "        p_sorted = []\n",
    "        a_sorted = []\n",
    "        \n",
    "        # prediction\n",
    "        tmp = df[df.name == res].sort_values(by=['pred_importance'],ascending=[False]).reset_index(drop=True)\n",
    "        p_sorted = get_ranking_list(tmp)\n",
    " \n",
    "        # true\n",
    "        ori_tmp = df[df.name == res].sort_values(by=['pair_importance'],ascending=[False]).reset_index(drop=True)\n",
    "        a_sorted = get_ranking_list(ori_tmp)\n",
    "        \n",
    "        \n",
    "        true_list.append(a_sorted)\n",
    "        true_rel.append()\n",
    "        pred_list.append(p_sorted)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    return pred_list, true_rel , true_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b243d39c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:21:02.575663Z",
     "start_time": "2023-04-27T07:21:02.570017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 9), (7, 5), (6, 8), (5, 8)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_list = [(5,8),(6,8),(7,5)]\n",
    "p_list.append((7,9))\n",
    "sorted(p_list,reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0441500c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:35:17.933299Z",
     "start_time": "2023-04-27T07:35:17.925412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(5, 8): 12, (6, 8): 11, (7, 5): 10}\n",
      "{(5, 8): 11, (6, 8): 12, (7, 5): 10}\n",
      "{(5, 8): 11, (6, 8): 12, (7, 5): 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(5, 8): 11, (6, 8): 12, (7, 5): 10}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_list = [(5,8),(6,8),(7,5)]\n",
    "p_dict = {}\n",
    "\n",
    "cnt =0\n",
    "for i in p_list:\n",
    "    p_dict[i] = 12-cnt\n",
    "    cnt+=1\n",
    "\n",
    "for i in range(len(p_list)):\n",
    "    print(p_dict)\n",
    "    for j in range(len(p_list)):\n",
    "        if i !=j:\n",
    "            if sorted(p_list[i] ,reverse=True) < sorted(p_list[j],reverse = True) and p_dict[p_list[i]] > p_dict[p_list[j]]:\n",
    "                tmp = p_dict[p_list[i]]\n",
    "                p_dict[p_list[i]] = p_dict[p_list[j]]\n",
    "                p_dict[p_list[j]] = tmp\n",
    "p_dict\n",
    "                      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d29f13b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:25:07.263310Z",
     "start_time": "2023-04-27T07:25:07.257753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((5,8),reverse = True) > sorted((6,8),reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20b022",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5635cee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T04:47:11.080374Z",
     "start_time": "2023-04-28T04:47:10.973398Z"
    }
   },
   "outputs": [],
   "source": [
    "# try\n",
    "train_features=['density', 'entropy', 'competitiveness','area_pop', 'accessibility','complementary']\n",
    "\n",
    "get_group_size = lambda df: df.reset_index().groupby(\"name\")['name'].count()\n",
    "\n",
    "train_groups = get_group_size(train_df).to_numpy()\n",
    "test_groups = get_group_size(test_df).to_numpy()\n",
    "# predict relevance score\n",
    "LGBM = LGBMRanker(objective=\"lambdarank\",random_state=RANDOM_STATE)\n",
    "LGBM.fit(train_df[train_features], train_df[['relevance']], group=train_groups)\n",
    "predict = LGBM.predict(test_df[train_features])\n",
    "test_df['pred_rel'] = predict\n",
    "\n",
    "# # predict importance\n",
    "# LR = LogisticRegression(random_state=RANDOM_STATE)\n",
    "# LR.fit(train_df[train_features], train_df[['pair_importance']])\n",
    "# predict = LR.predict(test_df[train_features])\n",
    "# test_df['pred_importance'] = predict\n",
    "\n",
    "# pred_list, pred_rel , true_list = get_ranking_pair(test_df,ori_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a5b1657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T04:47:16.366531Z",
     "start_time": "2023-04-28T04:47:16.344058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           name  loc_a  loc_b  density   entropy  \\\n",
      "0    Sakura Japanese Restaurant  37076  63053     65.0  3.483729   \n",
      "629  Sakura Japanese Restaurant  19020  37076     22.0  0.200665   \n",
      "\n",
      "     competitiveness  area_pop  accessibility  complementary  relevance  \\\n",
      "0                0.0    3998.0            0.0            0.0        1.0   \n",
      "629              0.0     431.0            0.0            0.0        0.0   \n",
      "\n",
      "     pair_importance  pred_rel  pred_importance  \n",
      "0                9.0  7.548513             12.0  \n",
      "629             17.0  2.411267             12.0  \n",
      "                name  loc_a  loc_b  density   entropy  competitiveness  \\\n",
      "1    Manhattan Bagel  19083  18914     37.0  1.108957              0.0   \n",
      "237  Manhattan Bagel  18914  08057    -21.0 -0.885920              0.0   \n",
      "338  Manhattan Bagel  08034  19083      6.0  0.233721              0.0   \n",
      "611  Manhattan Bagel  08057  93190     32.0  1.845827              0.0   \n",
      "\n",
      "     area_pop  accessibility  complementary  relevance  pair_importance  \\\n",
      "1      1410.0            0.0            0.0        0.0              9.0   \n",
      "237   -1775.0            0.0            0.0        1.0              7.0   \n",
      "338    1906.0            0.0            0.0        1.0             12.0   \n",
      "611    2286.0            0.0            0.0        1.0              2.0   \n",
      "\n",
      "     pred_rel  pred_importance  \n",
      "1   -1.387595             12.0  \n",
      "237  3.828058             21.0  \n",
      "338  1.847384             21.0  \n",
      "611  4.208177             12.0  \n",
      "                  name  loc_a  loc_b  density   entropy  competitiveness  \\\n",
      "2  Chicago Style Gyros  37216  89509   -119.0 -1.337848              0.0   \n",
      "\n",
      "   area_pop  accessibility  complementary  relevance  pair_importance  \\\n",
      "2  -10595.0            0.0            0.0        1.0             12.0   \n",
      "\n",
      "   pred_rel  pred_importance  \n",
      "2 -3.116672             21.0  \n",
      "         name  loc_a  loc_b  density   entropy  competitiveness  area_pop  \\\n",
      "3  Rush Bowls  85719  85614    188.0  2.216901              0.0   17469.0   \n",
      "\n",
      "   accessibility  complementary  relevance  pair_importance  pred_rel  \\\n",
      "3            0.0            0.0        1.0             10.0  2.884864   \n",
      "\n",
      "   pred_importance  \n",
      "3             12.0  \n",
      "                     name  loc_a  loc_b  density   entropy  competitiveness  \\\n",
      "4    Rusty's Pizza Parlor  93013  18940      7.0  0.103461              0.0   \n",
      "613  Rusty's Pizza Parlor  93101  93013    444.0  1.879014              0.0   \n",
      "\n",
      "     area_pop  accessibility  complementary  relevance  pair_importance  \\\n",
      "4      2663.0            0.0            0.0        1.0              8.0   \n",
      "613   57168.0            0.0            0.0        1.0             17.0   \n",
      "\n",
      "     pred_rel  pred_importance  \n",
      "4    0.884149             21.0  \n",
      "613  1.111307             11.0  \n"
     ]
    }
   ],
   "source": [
    "for i in Counter(test_df[:5].name):\n",
    "    tmp = test_df[test_df.name== i]\n",
    "    \n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ba40f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T15:33:20.633475Z",
     "start_time": "2023-04-26T15:33:20.624166Z"
    }
   },
   "outputs": [],
   "source": [
    "# models\n",
    "LR = LogisticRegression(random_state=RANDOM_STATE)\n",
    "RF = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "DTC = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "KNC = KNeighborsClassifier()\n",
    "SVC = svm.SVC(random_state=RANDOM_STATE)\n",
    "GNB = GaussianNB()\n",
    "LGBM = LGBMRanker(objective=\"lambdarank\",random_state=RANDOM_STATE)\n",
    "\n",
    "train_features=['density', 'entropy', 'competitiveness','area_pop', 'accessibility','complementary']\n",
    "\n",
    "get_group_size = lambda df: df.reset_index().groupby(\"name\")['name'].count()\n",
    "\n",
    "train_groups = get_group_size(train_df).to_numpy()\n",
    "test_groups = get_group_size(test_df).to_numpy()\n",
    "\n",
    "print(sum(train_groups) , sum(test_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d233f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T06:56:58.068692Z",
     "start_time": "2023-04-26T06:56:37.778429Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [LR, RF, DTC, KNC, SVC, GNB, LGBM]\n",
    "model_name =['LR', 'RF', 'DTC', 'KNC', 'SVC', 'GNB','LGBMRanker']\n",
    "score_dict = {}\n",
    "\n",
    "for i in range(len(models)):\n",
    "    score_dict[model_name[i]]={}\n",
    "    model = models[i]\n",
    "    # Train\n",
    "    if model_name[i] != 'LGBMRanker':\n",
    "        model.fit(train_df[train_features], train_df[['relevance']])\n",
    "    else:\n",
    "        model.fit(train_df[train_features], train_df[['relevance']], group=train_groups)\n",
    "    \n",
    "    # Predict\n",
    "    predict = model.predict(test_df[train_features])\n",
    "    test_df['predictions'] = predict\n",
    "    pred_list, pred_rel , true_list = get_ranking(test_df)\n",
    "\n",
    "    # Evaluation\n",
    "    mrr_list = calculate_mrr(pred_list , true_list)\n",
    "    map_list = calculate_map(pred_list , true_list)\n",
    "    dcg_list , ndcg_list = calculate_dcg_ndcg(pred_list , true_list,pred_rel)\n",
    "    precision_list_1 = _precision(pred_list , true_list, k=1)\n",
    "    recall_list_1 = _recall(pred_list , true_list,k=1)\n",
    "    precision_list_3 = _precision(pred_list , true_list, k=3)\n",
    "    recall_list_3 = _recall(pred_list , true_list,k=3)\n",
    "    precision_list = _precision(pred_list , true_list)\n",
    "    recall_list = _recall(pred_list , true_list)\n",
    "\n",
    "    score_dict[model_name[i]]['precision @ 1'] = np.mean(precision_list_1)\n",
    "    score_dict[model_name[i]]['recall @ 1'] = np.mean(recall_list_1)\n",
    "    score_dict[model_name[i]]['precision @ 3 '] = np.mean(precision_list_3)\n",
    "    score_dict[model_name[i]]['recall @ 3'] = np.mean(recall_list_3)\n",
    "    score_dict[model_name[i]]['precision'] = np.mean(precision_list)\n",
    "    score_dict[model_name[i]]['recall'] = np.mean(recall_list)\n",
    "    score_dict[model_name[i]]['mrr'] = np.mean(mrr_list)\n",
    "    score_dict[model_name[i]]['map'] = np.mean(map_list)\n",
    "    score_dict[model_name[i]]['dcg'] = np.mean(dcg_list)\n",
    "    score_dict[model_name[i]]['ndcg'] = np.mean(ndcg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3d87b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8a2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T06:56:58.079750Z",
     "start_time": "2023-04-26T06:56:58.069657Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(score_dict).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c021c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steph-env",
   "language": "python",
   "name": "steph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
