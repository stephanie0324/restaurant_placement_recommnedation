{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adopted-handling",
   "metadata": {},
   "source": [
    "# Create the features from Topic Modeling\n",
    "* using by_postal_code dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-tobago",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sublime-villa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:33.722463Z",
     "start_time": "2023-05-01T11:10:33.063089Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "southeast-sentence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:36.267151Z",
     "start_time": "2023-05-01T11:10:36.261144Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pacific-journey",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:38.285164Z",
     "start_time": "2023-05-01T11:10:36.757224Z"
    }
   },
   "outputs": [],
   "source": [
    "# 導入資料\n",
    "train_df = pd.read_pickle('/home/adam/Steph_C/my_thesis/data/Train_by_postoal_code_without_review_pointwise_v3_3.pkl')\n",
    "test_df = pd.read_pickle('/home/adam/Steph_C/my_thesis/data/Test_by_postoal_code_without_review_pointwise_v3_3.pkl')\n",
    "all_df = pd.read_pickle('../Data/yelp/restaurant_only.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "accepted-maker",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:41.639433Z",
     "start_time": "2023-05-01T11:10:41.446880Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "all_df = all_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "vital-mining",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:42.166024Z",
     "start_time": "2023-05-01T11:10:42.160509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5766, 27) (3473, 27) (2112553, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape , test_df.shape , all_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-meaning",
   "metadata": {},
   "source": [
    "# Create Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "equal-assembly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:51:29.658123Z",
     "start_time": "2023-05-01T11:51:29.652659Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pyLDAvis.gensim_models\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import matutils\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "collective-clark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:45.819087Z",
     "start_time": "2023-05-01T11:10:45.819078Z"
    }
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE \n",
    "# import spacy\n",
    "# from spacy.lang.en.examples import sentences \n",
    "\n",
    "# # nlp = spacy.load(\"en_core_web_md\")\n",
    "# # doc = nlp(sentences[0])\n",
    "# # print(doc.text)\n",
    "# # for token in doc:\n",
    "# #     print(token.text, token.pos_, token.dep_)\n",
    "\n",
    "# print(sentences)\n",
    "\n",
    "# dictionary = Dictionary([preprocess(''.join(sentences))])\n",
    "# print(dictionary)\n",
    "# # dictionary.filter_extremes(no_below=5, no_above=0.9, keep_n=100)\n",
    "# corpus = [dictionary.doc2bow(doc) for doc in [preprocess(''.join(sentences))]]\n",
    "# print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "permanent-event",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:49.276014Z",
     "start_time": "2023-05-01T11:10:48.525179Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "keep_pos = ['NOUN','ADJ','ADV','VERB']\n",
    "# removal= ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']\n",
    "\n",
    "def preprocess(text : str) -> list:\n",
    "    \n",
    "    for summary in nlp.pipe([text]):\n",
    "        proj_tok = [token.lemma_.lower() for token in summary \\\n",
    "                    if token.pos_ in keep_pos and not token.is_stop and token.is_alpha]\n",
    "\n",
    "    return proj_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "regulation-grounds",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:57.511614Z",
     "start_time": "2023-05-01T11:10:57.506044Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_attribute_tokens(df):\n",
    "    \n",
    "    attribute_list = ['Ambience' , 'GoodForMeal' ]\n",
    "    att_list = []\n",
    "    df = df.reset_index(drop= True)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            for k,v in df.attributes[i].items():\n",
    "                if k in attribute_list:\n",
    "                    if isinstance(v,dict):\n",
    "                        for k_1 , v_1 in v.items():\n",
    "                            if v_1:\n",
    "                                att_list.append(k_1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return att_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "sunset-accent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:58.104928Z",
     "start_time": "2023-05-01T11:10:58.097091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create tokens\n",
    "def get_tokens(df):\n",
    "    \n",
    "    df['res_tokens'] = ''\n",
    "    df['loc_tokens'] = ''\n",
    "    df['res_tokens_with_att'] = ''\n",
    "    df['loc_tokens_with_att'] = ''\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        res_str = ''\n",
    "        loc_str = ''\n",
    "\n",
    "        res = df[df.name==df.name[i]]\n",
    "        res = res[res.postal_code != df.postal_code[i]]\n",
    "\n",
    "        loc = df[df.postal_code==df.postal_code[i]]\n",
    "        loc = loc[loc.name != df.name[i]]\n",
    "\n",
    "        # get res_string\n",
    "        for j in Counter(res.text):\n",
    "            removed = []\n",
    "            if j not in removed:\n",
    "                res_str+=j+' '\n",
    "                removed.append(j)\n",
    "\n",
    "        # get loc_string\n",
    "        for j in Counter(loc.text):\n",
    "            removed = []\n",
    "            if j not in removed:\n",
    "                loc_str+=j+' '\n",
    "                removed.append(j)\n",
    "        \n",
    "        # get attributes tokens\n",
    "        res_att = get_attribute_tokens(res)\n",
    "        loc_att = get_attribute_tokens(loc)\n",
    "        \n",
    "        orig_list_res = preprocess(res_str)\n",
    "        orig_list_loc = preprocess(loc_str)\n",
    "        \n",
    "        df['res_tokens'][i] = orig_list_res\n",
    "        df['loc_tokens'][i] = orig_list_loc\n",
    "        \n",
    "        df['res_tokens_with_att'][i] = orig_list_res+res_att\n",
    "        df['loc_tokens_with_att'][i] = orig_list_loc+loc_att\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    print(f'Finish building .....')\n",
    "    \n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "optimum-foster",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:41:51.737705Z",
     "start_time": "2023-05-01T11:10:58.626006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building .....\n"
     ]
    }
   ],
   "source": [
    "# Takes a LONG time\n",
    "train_df = get_tokens(train_df)\n",
    "test_df = get_tokens(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-desktop",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "active-problem",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T12:30:20.738719Z",
     "start_time": "2023-05-01T12:30:20.718720Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_LDA(train_df , test_df ,tokens):\n",
    "    \n",
    "    train_df['LDA_'+tokens] = ''\n",
    "    test_df['LDA_'+tokens] = ''\n",
    "    dictionary = Dictionary(train_df[tokens])\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=1000)\n",
    "    \n",
    "    #### doc2Bow\n",
    "    train_corpus = [dictionary.doc2bow(doc) for doc in train_df[tokens]]\n",
    "    test_corpus = [dictionary.doc2bow(doc) for doc in test_df[tokens]]\n",
    "\n",
    "    # building models\n",
    "    lda_model = LdaMulticore(corpus=train_corpus, id2word=dictionary, iterations=50, \\\n",
    "                             num_topics=10, workers = 4, passes=10)\n",
    "    \n",
    "    for i in range(len(train_corpus)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        train_df['LDA_'+tokens][i] = lda_model[train_corpus][i]\n",
    "\n",
    "    print(f'Finish building train .....')\n",
    "    \n",
    "    for i in range(len(test_corpus)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        test_df['LDA_'+tokens][i] = lda_model[test_corpus][i]\n",
    "\n",
    "    print(f'Finish building test .....')\n",
    "    return train_df , test_df , lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "persistent-portsmouth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:32:46.468088Z",
     "start_time": "2023-05-01T13:32:46.459965Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_LDA_tfidf(train_df , test_df,tokens ):\n",
    "    \n",
    "    train_df['LDA_'+tokens+'_tfidf'] = ''\n",
    "    test_df['LDA_'+tokens+'_tfidf'] = ''\n",
    "\n",
    "    vectorizer = TfidfVectorizer(min_df=10, max_df=0.2, max_features=1000)\n",
    "    \n",
    "    #### TF-IDF\n",
    "    train_documents = [' '.join(tokens) for tokens in list(train_df[tokens])]\n",
    "    test_documents = [' '.join(tokens) for tokens in list(test_df[tokens])]\n",
    "\n",
    "    train_corpus = matutils.Sparse2Corpus(vectorizer.fit_transform(train_documents).T)\n",
    "    test_corpus = matutils.Sparse2Corpus(vectorizer.fit_transform(test_documents).T)\n",
    "    \n",
    "    \n",
    "    # building models\n",
    "    id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "    lda_model = LdaMulticore(corpus=train_corpus, id2word=id2word, iterations=50, \\\n",
    "                             num_topics=10, workers = 4, passes=10)\n",
    "    \n",
    "    for i in range(len(train_corpus)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        train_df['LDA_'+tokens+'_tfidf'][i] = lda_model[train_corpus][i]\n",
    "\n",
    "    print(f'Finish building train .....')\n",
    "    \n",
    "    for i in range(len(test_corpus)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        test_df['LDA_'+tokens+'_tfidf'][i] = lda_model[test_corpus][i]\n",
    "\n",
    "    print(f'Finish building test .....')\n",
    "    return train_df , test_df , lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "documented-netscape",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:32:50.812099Z",
     "start_time": "2023-05-01T13:32:47.261519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building train .....\n",
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building test .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building train .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building test .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building train .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building test .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building train .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building test .....\n"
     ]
    }
   ],
   "source": [
    "train_df ,test_df , res_lda = get_LDA(train_df ,test_df , 'res_tokens')\n",
    "train_df ,test_df , res_lda_w_attr = get_LDA(train_df ,test_df , 'res_tokens_with_att')\n",
    "train_df ,test_df , loc_lda = get_LDA(train_df ,test_df , 'loc_tokens')\n",
    "train_df ,test_df , loc_lda_w_attr = get_LDA(train_df ,test_df , 'loc_tokens_with_att')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "interstate-sussex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:33:51.392039Z",
     "start_time": "2023-05-01T13:32:52.941175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building train .....\n",
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building test .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building train .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building test .....\n"
     ]
    }
   ],
   "source": [
    "train_df ,test_df , res_lda_tfidf = get_LDA_tfidf(train_df ,test_df , 'res_tokens_with_att')\n",
    "train_df ,test_df , loc_lda_tfidf = get_LDA_tfidf(train_df ,test_df , 'loc_tokens_with_att')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "absolute-rwanda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:36:31.786702Z",
     "start_time": "2023-05-01T13:36:31.774486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"egg\" + 0.016*\"plan\" + 0.015*\"brisket\" + 0.011*\"rabe\" + 0.010*\"edginess\" + 0.010*\"crowd\" + 0.008*\"gate\" + 0.008*\"surprise\" + 0.008*\"pineapple\" + 0.008*\"eater\"'),\n",
       " (1,\n",
       "  '0.013*\"guac\" + 0.012*\"baby\" + 0.011*\"tail\" + 0.010*\"bag\" + 0.009*\"computer\" + 0.007*\"driver\" + 0.007*\"tonight\" + 0.007*\"drip\" + 0.007*\"use\" + 0.006*\"daughter\"'),\n",
       " (2,\n",
       "  '0.050*\"plan\" + 0.014*\"dollar\" + 0.012*\"potato\" + 0.012*\"garage\" + 0.011*\"floor\" + 0.010*\"sever\" + 0.010*\"watery\" + 0.010*\"wonton\" + 0.009*\"tropichop\" + 0.008*\"trip\"'),\n",
       " (3,\n",
       "  '0.019*\"tire\" + 0.017*\"combo\" + 0.013*\"sever\" + 0.010*\"sister\" + 0.009*\"garage\" + 0.008*\"pan\" + 0.008*\"temp\" + 0.008*\"face\" + 0.008*\"soy\" + 0.008*\"sausage\"'),\n",
       " (4,\n",
       "  '0.015*\"boba\" + 0.014*\"rule\" + 0.011*\"pound\" + 0.011*\"thought\" + 0.010*\"hospitality\" + 0.009*\"pan\" + 0.009*\"tire\" + 0.009*\"surprise\" + 0.008*\"eater\" + 0.008*\"soy\"'),\n",
       " (5,\n",
       "  '0.022*\"sever\" + 0.014*\"wonton\" + 0.011*\"baby\" + 0.010*\"grit\" + 0.010*\"stay\" + 0.010*\"buck\" + 0.009*\"onion\" + 0.009*\"fact\" + 0.009*\"bathroom\" + 0.009*\"seed\"'),\n",
       " (6,\n",
       "  '0.101*\"plan\" + 0.018*\"dollar\" + 0.014*\"desk\" + 0.010*\"night\" + 0.010*\"pesto\" + 0.010*\"industry\" + 0.009*\"driver\" + 0.009*\"bottle\" + 0.009*\"wife\" + 0.008*\"tomato\"'),\n",
       " (7,\n",
       "  '0.019*\"grit\" + 0.011*\"table\" + 0.011*\"stay\" + 0.011*\"default\" + 0.011*\"bubble\" + 0.011*\"juiciness\" + 0.009*\"sever\" + 0.008*\"box\" + 0.008*\"breakfast\" + 0.008*\"highway\"'),\n",
       " (8,\n",
       "  '0.022*\"watery\" + 0.021*\"surprise\" + 0.014*\"raspberry\" + 0.012*\"stick\" + 0.010*\"chocolate\" + 0.010*\"buck\" + 0.008*\"green\" + 0.008*\"room\" + 0.008*\"box\" + 0.008*\"juiciness\"'),\n",
       " (9,\n",
       "  '0.025*\"bubble\" + 0.013*\"plan\" + 0.012*\"issue\" + 0.010*\"chick\" + 0.010*\"grit\" + 0.009*\"bell\" + 0.009*\"fan\" + 0.009*\"equivalent\" + 0.008*\"driver\" + 0.008*\"fryer\"')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_lda_tfidf.print_topics(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "black-sleeve",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:36:34.746630Z",
     "start_time": "2023-05-01T13:36:34.734229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"transpire\" + 0.013*\"rangoon\" + 0.012*\"latte\" + 0.011*\"kettle\" + 0.011*\"raspberry\" + 0.011*\"rush\" + 0.011*\"breast\" + 0.010*\"excuse\" + 0.010*\"dine\" + 0.010*\"representative\"'),\n",
       " (1,\n",
       "  '0.042*\"gift\" + 0.028*\"arugula\" + 0.027*\"picture\" + 0.027*\"patio\" + 0.025*\"tradition\" + 0.025*\"goal\" + 0.024*\"nature\" + 0.022*\"bomb\" + 0.021*\"greatness\" + 0.019*\"scrap\"'),\n",
       " (2,\n",
       "  '0.014*\"recommendation\" + 0.013*\"celiac\" + 0.013*\"pain\" + 0.013*\"chaos\" + 0.012*\"lobby\" + 0.012*\"fork\" + 0.012*\"olive\" + 0.011*\"staple\" + 0.011*\"folk\" + 0.011*\"grin\"'),\n",
       " (3,\n",
       "  '0.026*\"dad\" + 0.013*\"tikka\" + 0.013*\"tray\" + 0.010*\"skimping\" + 0.009*\"date\" + 0.009*\"muffin\" + 0.008*\"rotation\" + 0.008*\"math\" + 0.008*\"mozzarella\" + 0.008*\"mother\"'),\n",
       " (4,\n",
       "  '0.041*\"drizzle\" + 0.035*\"eating\" + 0.029*\"thank\" + 0.028*\"stay\" + 0.023*\"dad\" + 0.022*\"trip\" + 0.021*\"mark\" + 0.017*\"brocoli\" + 0.016*\"skin\" + 0.015*\"alcohol\"'),\n",
       " (5,\n",
       "  '0.015*\"system\" + 0.012*\"trip\" + 0.010*\"robot\" + 0.010*\"shot\" + 0.010*\"sit\" + 0.009*\"break\" + 0.008*\"punch\" + 0.008*\"fajita\" + 0.008*\"good\" + 0.008*\"happening\"'),\n",
       " (6,\n",
       "  '0.010*\"mood\" + 0.010*\"bunch\" + 0.010*\"raman\" + 0.009*\"nugget\" + 0.009*\"past\" + 0.007*\"meh\" + 0.007*\"transpire\" + 0.007*\"calculator\" + 0.007*\"snapper\" + 0.006*\"drum\"'),\n",
       " (7,\n",
       "  '0.014*\"leftover\" + 0.012*\"chilaquile\" + 0.012*\"brownie\" + 0.011*\"downtown\" + 0.011*\"license\" + 0.009*\"buffet\" + 0.008*\"gal\" + 0.008*\"mood\" + 0.008*\"teriyaki\" + 0.008*\"sound\"'),\n",
       " (8,\n",
       "  '0.015*\"mozzarella\" + 0.014*\"patty\" + 0.013*\"offer\" + 0.013*\"focaccia\" + 0.013*\"feta\" + 0.012*\"school\" + 0.011*\"fanatic\" + 0.010*\"frustration\" + 0.010*\"answer\" + 0.010*\"host\"'),\n",
       " (9,\n",
       "  '0.019*\"vinegar\" + 0.018*\"web\" + 0.016*\"broccoli\" + 0.016*\"raspberry\" + 0.016*\"fault\" + 0.016*\"consistency\" + 0.014*\"poisoning\" + 0.014*\"chile\" + 0.013*\"card\" + 0.013*\"cut\"')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_lda_tfidf.print_topics(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-colony",
   "metadata": {},
   "source": [
    "## Cal Cosine Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "sensitive-value",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T07:56:52.512806Z",
     "start_time": "2023-05-01T07:56:52.512781Z"
    }
   },
   "outputs": [],
   "source": [
    "# from gensim.matutils import cossim\n",
    "# # Return cosine similarity between two sparse vectors. \n",
    "# # The similarity is a number between <-1.0, 1.0>, higher is more similar.\n",
    "# print(cossim(train_df.LDA_res_tokens[1], train_df.LDA_loc_tokens[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "closing-african",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:03:20.089406Z",
     "start_time": "2023-05-01T14:03:20.083325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'stars_x', 'useful', 'funny', 'cool', 'text', 'date',\n",
       "       'name', 'address', 'city', 'state', 'postal_code', 'latitude',\n",
       "       'longitude', 'stars_y', 'review_count', 'is_open', 'attributes',\n",
       "       'categories', 'hours', 'relevance', 'density', 'entropy', 'area_pop',\n",
       "       'accessibility', 'complementary', 'competitiveness', 'res_tokens',\n",
       "       'loc_tokens', 'res_tokens_with_att', 'loc_tokens_with_att',\n",
       "       'LDA_res_tokens', 'LDA_res_tokens_with_att', 'LDA_loc_tokens',\n",
       "       'LDA_loc_tokens_with_att', 'LDA_res_tokens_with_att_tfidf',\n",
       "       'LDA_loc_tokens_with_att_tfidf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "relative-wrist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:03:58.295837Z",
     "start_time": "2023-05-01T14:03:58.290320Z"
    }
   },
   "outputs": [],
   "source": [
    "# create Affinity and Complementary\n",
    "from gensim.matutils import cossim\n",
    "\n",
    "def get_cos_sim(df):\n",
    "    \n",
    "    df['tok_cosine_sim'] =''\n",
    "    df['tok_cosine_sim_w_attr'] =''\n",
    "    df['tok_cosine_sim_tfidf'] =''\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        df['tok_cosine_sim'][i] = cossim(df.LDA_res_tokens[i], df.LDA_loc_tokens[i])\n",
    "        df['tok_cosine_sim_w_attr'][i] = cossim(df.LDA_res_tokens_with_att[i], df.LDA_loc_tokens_with_att[i])\n",
    "        df['tok_cosine_sim_tfidf'][i] = cossim(df.LDA_res_tokens_with_att_tfidf[i], df.LDA_loc_tokens_with_att_tfidf[i])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "electoral-owner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:04:05.761977Z",
     "start_time": "2023-05-01T14:03:59.777417Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "train_df = get_cos_sim(train_df)\n",
    "test_df = get_cos_sim(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-hampshire",
   "metadata": {},
   "source": [
    "## Affinity & Complementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "saved-ranking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:10:07.955853Z",
     "start_time": "2023-05-01T14:10:07.948597Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_aff_comp(df) : \n",
    "    \n",
    "    df['tok_affinity'] = ''\n",
    "    df['tok_complementary'] = ''\n",
    "    df['tok_affinity_with_att'] = ''\n",
    "    df['tok_complementary_with_att'] = ''\n",
    "    df['tok_affinity_tfidf'] = ''\n",
    "    df['tok_complementary_tfidf'] = ''\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        affinity = 0\n",
    "        complementary = 0\n",
    "        affinity_with_att = 0\n",
    "        complementary_with_att = 0\n",
    "        affinity_tfidf = 0\n",
    "        complementary_tfidf = 0\n",
    "        \n",
    "        for j in df.LDA_res_tokens[i]:\n",
    "            for k in df.LDA_loc_tokens[i]: \n",
    "                if j[0] in k:\n",
    "                    affinity += j[1]*k[1]\n",
    "                    complementary += j[1]*(1-k[1])\n",
    "        \n",
    "        \n",
    "        for j in df.LDA_res_tokens_with_att[i]:\n",
    "            for k in df.LDA_loc_tokens_with_att[i]: \n",
    "                if j[0] in k:\n",
    "                    affinity_with_att += j[1]*k[1]\n",
    "                    complementary_with_att += j[1]*(1-k[1]) \n",
    "        \n",
    "        for j in df.LDA_res_tokens_with_att_tfidf[i]:\n",
    "            for k in df.LDA_loc_tokens_with_att_tfidf[i]: \n",
    "                if j[0] in k:\n",
    "                    affinity_tfidf += j[1]*k[1]\n",
    "                    complementary_tfidf += j[1]*(1-k[1]) \n",
    "        \n",
    "        df['tok_affinity'][i] = affinity\n",
    "        df['tok_complementary'][i] = complementary\n",
    "        df['tok_affinity_with_att'][i] = affinity_with_att\n",
    "        df['tok_complementary_with_att'][i] = complementary_with_att\n",
    "        df['tok_affinity_tfidf'][i] = affinity_tfidf\n",
    "        df['tok_complementary_tfidf'][i] = complementary_tfidf\n",
    "        \n",
    "    return df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "electric-satisfaction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:10:22.078791Z",
     "start_time": "2023-05-01T14:10:09.970125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train_df = get_aff_comp(train_df)\n",
    "test_df = get_aff_comp(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "saving-penny",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:10:31.215044Z",
     "start_time": "2023-05-01T14:10:31.202575Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in ['tok_affinity','tok_complementary','tok_affinity_with_att','tok_complementary_with_att','tok_cosine_sim','tok_affinity_tfidf','tok_complementary_tfidf']:\n",
    "    train_df[i] = train_df[i].astype('float')\n",
    "    test_df[i] = test_df[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "limiting-think",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:10:39.922194Z",
     "start_time": "2023-05-01T14:10:36.737294Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle('/home/adam/Steph_C/my_thesis/data/Train_by_postoal_code_pointwise_v3_3_tfidf.pkl')\n",
    "test_df.to_pickle('/home/adam/Steph_C/my_thesis/data/Test_by_postoal_code_pointwise_v3_3_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-characteristic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steph_env",
   "language": "python",
   "name": "steph_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
