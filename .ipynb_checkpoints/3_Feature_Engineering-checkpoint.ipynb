{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8d5b21",
   "metadata": {},
   "source": [
    "# Create the features DF\n",
    "* using by_postal_code dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec941861",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b42150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:11.667826Z",
     "start_time": "2023-04-19T14:36:11.020291Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import sparse as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0857e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:13.804767Z",
     "start_time": "2023-04-19T14:36:13.798236Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba49a623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:16.708985Z",
     "start_time": "2023-04-19T14:36:14.474915Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df = pd.read_pickle ('/home/adam/Steph_C/my_thesis/data/ORI_by_postal_code_s_dropped.pkl').reset_index(drop=True)\n",
    "venue_df = pd.read_pickle ('../Data/yelp/other_venues.pkl').reset_index(drop=True)\n",
    "all_df = pd.read_pickle('../Data/yelp/restaurant_only.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca19685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:17.763556Z",
     "start_time": "2023-04-19T14:36:17.758162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192547, 20) (700010, 20) (2112553, 20)\n"
     ]
    }
   ],
   "source": [
    "print(res_df.shape , venue_df.shape , all_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb1aa06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:23.561943Z",
     "start_time": "2023-04-19T14:36:22.739460Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df = pd.concat([all_df,venue_df]) # for check in calculation\n",
    "res_df = res_df.drop_duplicates(subset=['name','postal_code']).reset_index(drop=True)\n",
    "venue_df = venue_df.drop_duplicates(subset=['name','postal_code']).reset_index(drop=True)\n",
    "all_df = all_df.drop_duplicates(subset=['name','postal_code']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b65244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:24.304082Z",
     "start_time": "2023-04-19T14:36:24.200870Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop postal_codes not in U.S\n",
    "drop_postal = [i for i in range(len(all_df)) if not all_df.postal_code[i].isdigit()]\n",
    "all_df = all_df.drop(drop_postal).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2818825d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:26.323788Z",
     "start_time": "2023-04-19T14:36:26.314671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1848, 20) (14791, 20) (2812563, 20) (19901, 20)\n"
     ]
    }
   ],
   "source": [
    "print(res_df.shape , venue_df.shape , df.shape , all_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0acff32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:38:45.565233Z",
     "start_time": "2023-04-19T14:38:45.546617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(res_df.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d0e67b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:38:48.057743Z",
     "start_time": "2023-04-19T14:38:47.050967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance score added\n"
     ]
    }
   ],
   "source": [
    "# create relevance score\n",
    "cnt = 0\n",
    "new_df = pd.DataFrame()\n",
    "for i in Counter(res_df.name):\n",
    "    tmp = res_df[res_df.name==i].reset_index(drop=True)\n",
    "    tmp['relevance']=''\n",
    "    score = 12\n",
    "    for j in range(len(tmp)):\n",
    "        tmp['relevance'][j]=score\n",
    "        score -=1\n",
    "    new_df = pd.concat([new_df,tmp])\n",
    "\n",
    "# check the shape\n",
    "if new_df.shape[0] != res_df.shape[0]:\n",
    "    print(f'There is a mistake creating the relevance score')\n",
    "else:\n",
    "    print(f'Relevance score added')\n",
    "res_df = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "870420f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:42:54.001182Z",
     "start_time": "2023-04-19T14:38:49.694683Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a overall postal_code features\n",
    "# postal code and feature dict\n",
    "postal_code_feature_dict = {}\n",
    "\n",
    "for postal in Counter(all_df.postal_code):\n",
    "    \n",
    "    postal_code_feature_dict[postal]={}\n",
    "    tmp = df[df.postal_code == postal].reset_index(drop=True)\n",
    "    tmp_venue = venue_df[venue_df == postal].reset_index(drop=True)\n",
    "    \n",
    "    # density \n",
    "    postal_code_feature_dict[postal]['density'] = len(Counter(tmp.name))\n",
    "    \n",
    "    # neighborhood_entropy\n",
    "    entropy_sum = 0\n",
    "    for category in Counter(tmp.categories):\n",
    "        entropy_sum+=(len(Counter(tmp[tmp.categories==category].name))/len(Counter(tmp.name)))\\\n",
    "        *np.log(len(Counter(tmp[tmp.categories==category].name))/len(Counter(tmp.name)))\n",
    "    postal_code_feature_dict[postal]['entropy'] = -entropy_sum\n",
    "    \n",
    "    # area popularity\n",
    "    postal_code_feature_dict[postal]['area_pop'] = len(tmp)\n",
    "    \n",
    "    # traffic accessibility + complementary\n",
    "    transportation_cnt = 0\n",
    "    dep_cnt = 0\n",
    "    parking_cnt =0\n",
    "    \n",
    "    store_cnt = len(Counter(tmp_venue.name))\n",
    "    \n",
    "    for i in range(len(tmp_venue)):\n",
    "        try:\n",
    "            if 'Public Transportation' in tmp_venue.categories[i]:\n",
    "                transportation_cnt+=1\n",
    "            if 'Department Stores' in tmp_venue.categories[i]:\n",
    "                dep_cnt+=1\n",
    "            if 'Parking' in tmp_venue.categories[i]:\n",
    "                parking_cnt+=1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    postal_code_feature_dict[postal]['accessibility'] = transportation_cnt\n",
    "    if store_cnt >1:\n",
    "        postal_code_feature_dict[postal]['complementary'] = (2*(dep_cnt+parking_cnt) )/(store_cnt*(store_cnt-1)) \n",
    "    else:\n",
    "        postal_code_feature_dict[postal]['complementary']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19598ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:46:49.322280Z",
     "start_time": "2023-04-19T14:46:49.316438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(postal_code_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff23513",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.194Z"
    }
   },
   "outputs": [],
   "source": [
    "# # # to check the features\n",
    "# postal_df = pd.DataFrame(postal_code_feature_dict).T.reset_index().rename(columns={'index': 'postal_code'})\n",
    "# postal_df\n",
    "# # Counter(postal_df.complementary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c067a7",
   "metadata": {},
   "source": [
    "# Train Test Split with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7f555c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:46:51.546856Z",
     "start_time": "2023-04-19T14:46:51.540782Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_new (new ,category,postal, all_df, postal_df):\n",
    "    \n",
    "    new = new.drop(columns=['density', 'entropy','area_pop', 'accessibility', 'complementary'])\n",
    "    new['postal_code'] = postal\n",
    "    new = pd.DataFrame(new.merge(postal_df, on='postal_code', how='left'))\n",
    "    new['relevance'] = 0\n",
    "    # add competitiveness\n",
    "    new['competitiveness']=''\n",
    "    place = all_df[all_df.postal_code == postal].reset_index(drop=True)\n",
    "    new['competitiveness'] = -(len(Counter(place[place.categories == category].name))\\\n",
    "                                  /len(Counter(place.name)))\n",
    "    # TO-DO Add reviews\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5499f7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pointwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e6800",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.199Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # POINTWISE v1\n",
    "# # split train test \n",
    "# # 拿每一個餐廳一半的分店當作 testing set (雖然大部分只有兩家分店)\n",
    "\n",
    "# cnt = 0\n",
    "# train_df = pd.DataFrame()\n",
    "# test_df = pd.DataFrame()\n",
    "# pos_train_post = Counter()\n",
    "# neg_train_post ={}\n",
    "\n",
    "# for i in Counter(res_df.name):\n",
    "    \n",
    "    \n",
    "#     tmp = res_df[res_df.name==i]\n",
    "#     tmp_train , tmp_test = train_test_split(tmp, test_size=0.33, shuffle= True,random_state=RANDOM_STATE)\n",
    "    \n",
    "#     postal_df = pd.DataFrame(postal_code_feature_dict).T.reset_index().rename(columns={'index': 'postal_code'})\n",
    "#     postal_df = postal_df.sort_values(['postal_code'],\n",
    "#               ascending = [True]).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "#     # merge with location features\n",
    "#     tmp_train = pd.DataFrame(tmp_train.merge(postal_df, on='postal_code', how='left')).reset_index(drop=True)\n",
    "#     tmp_test = pd.DataFrame(tmp_test.merge(postal_df, on='postal_code', how='left')).reset_index(drop=True)\n",
    "    \n",
    "#     pos_train_post += Counter(tmp_train.postal_code)\n",
    "#     ori_train, ori_test = tmp_train.shape , tmp_test.shape\n",
    "    \n",
    "#     ############################## reconstruct ################################\n",
    "#     postal_codes_list_train = list(postal_df.postal_code)\n",
    "#     postal_codes_list_test= list(postal_df.postal_code)\n",
    "    \n",
    "    \n",
    "#     for j in Counter(tmp_train.postal_code):\n",
    "#         postal_codes_list_train.remove(j)\n",
    "#         postal_codes_list_test.remove(j)\n",
    "    \n",
    "#     for j in Counter(tmp_test.postal_code):\n",
    "#         postal_codes_list_train.remove(j)\n",
    "#         postal_codes_list_test.remove(j)\n",
    "    \n",
    "    \n",
    "#     ## train \n",
    "#     tmp_train['competitiveness'] =''\n",
    "#     neg_df = pd.DataFrame()\n",
    "    \n",
    "#     for j in range(len(tmp_train)):\n",
    "        \n",
    "#         cnt =0 \n",
    "#         category = tmp_train.categories[j]\n",
    "\n",
    "        \n",
    "#         # add competitiveness\n",
    "#         place = all_df[all_df.postal_code == tmp_train['postal_code'][j]]\n",
    "#         tmp_train['competitiveness'][j] = -(len(Counter(place[place.categories == category].name))/len(Counter(place.name)))\n",
    "    \n",
    "#         ## TO-DO Add reviews \n",
    "        \n",
    "#         # add the negative samples\n",
    "#         for k in range(len(postal_df)):\n",
    "#             if cnt<2:\n",
    "#                 if postal_df.postal_code[k] in postal_codes_list_train and\\\n",
    "#                 abs(int(postal_df.postal_code[k])- int(tmp_train['postal_code'][j])) <= 1000:\n",
    "#                     cnt+=1\n",
    "#                     new = pd.DataFrame(tmp_train.iloc[j]).T.reset_index(drop=True)\n",
    "#                     new = create_new (new ,category, all_df, postal_df)\n",
    "#                     neg_df = pd.concat([neg_df ,new ])\n",
    "    \n",
    "#                     ##### create a negative sample dict\n",
    "#                     if postal_df.postal_code[k] in neg_train_post:\n",
    "#                         neg_train_post[postal_df.postal_code[k]] +=1\n",
    "#                     else:\n",
    "#                         neg_train_post[postal_df.postal_code[k]]=1\n",
    "#             else:\n",
    "#                 break\n",
    "    \n",
    "#     tmp_train = pd.concat([tmp_train ,neg_df ])\n",
    "    \n",
    "#     ## test \n",
    "    \n",
    "#     tmp_test['competitiveness'] =''\n",
    "    \n",
    "#     neg_df = pd.DataFrame()\n",
    "#     for j in range(len(tmp_test)):\n",
    "#         cnt =0\n",
    "#         category = tmp_test.categories[j]\n",
    "#         # add competitiveness\n",
    "#         place = all_df[all_df.postal_code == tmp_test['postal_code'][j]]\n",
    "#         tmp_test['competitiveness'][j] = -(len(Counter(place[place.categories == tmp_test.categories[j]].name))/len(Counter(place.name)))\n",
    "        \n",
    "#         # TO-DO add review \n",
    "        \n",
    "#         # add negative samples\n",
    "#         for k in range(len(postal_df)):\n",
    "#             if cnt<2:\n",
    "#                 if postal_df.postal_code[k] in postal_codes_list_test and\\\n",
    "#                 abs(int(postal_df.postal_code[k])-int(tmp_test['postal_code'][j])) <= 1000:\n",
    "#                     cnt+=1\n",
    "#                     new = pd.DataFrame(tmp_test.iloc[j]).T.reset_index(drop=True)\n",
    "#                     new = create_new (new ,category, all_df, postal_df)\n",
    "#                     neg_df = pd.concat([neg_df ,new ])\n",
    "#             else:\n",
    "#                 break\n",
    "                \n",
    "#     tmp_test = pd.concat([tmp_test ,neg_df ])   \n",
    "#     if int(tmp_train.shape[0]) != int(ori_train[0]*3) or int(tmp_test.shape[0]) != int(ori_test[0]*3):\n",
    "#         print('Original: ' ,ori_train, ori_test )\n",
    "#         print('After : ',tmp_train.shape[0] , tmp_test.shape[0])\n",
    "#         print(f'There is sth wrong !!!!!!!!')\n",
    "#         break\n",
    "    \n",
    "#     train_df =  pd.concat([train_df ,tmp_train ])\n",
    "#     test_df =  pd.concat([test_df ,tmp_test ])\n",
    "# print(f'Finished constructing....  train : {len(Counter(train_df.name))} test : {len(Counter(test_df.name))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e9073",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # # POINTWISE v2\n",
    "# # # 取每間餐廳分店中郵遞區號最大，取其 +-500 的所有地區 再去切 train test\n",
    "# # # split train test \n",
    "# train_df = pd.DataFrame()\n",
    "# test_df = pd.DataFrame()\n",
    "\n",
    "# for i in Counter(res_df.name):\n",
    "    \n",
    "#     tmp = res_df[res_df.name==i].sort_values(['postal_code'],ascending = [False]).reset_index(drop=True)\n",
    "#     max_postal = max(tmp.postal_code.astype(int))\n",
    "#     category = tmp.categories[0]\n",
    "#     postal_df = pd.DataFrame(postal_code_feature_dict).T.reset_index().rename(columns={'index': 'postal_code'})\n",
    "#     postal_df = postal_df.sort_values(['postal_code'],ascending = [True]).reset_index(drop=True)\n",
    "#     postal_codes_list = list(postal_df.postal_code)\n",
    "    \n",
    "#     # remove the known postal codes\n",
    "#     for postal in Counter(tmp.postal_code):\n",
    "#         postal_codes_list.remove(postal)\n",
    "\n",
    "#     # merge with location features\n",
    "#     tmp = pd.DataFrame(tmp.merge(postal_df, on='postal_code', how='left')).reset_index(drop=True)\n",
    "    \n",
    "#     # add competitiveness and review (TO-DO)\n",
    "#     tmp['competitiveness']= ''\n",
    "# #     tmp['review']= ''\n",
    "#     for j in range(len(tmp)):\n",
    "        \n",
    "#         # competitiveness\n",
    "#         place = all_df[all_df.postal_code == tmp['postal_code'][j]]\n",
    "#         tmp['competitiveness'][j] = -(len(Counter(place[place.categories == category].name))/len(Counter(place.name)))\n",
    "\n",
    "    \n",
    "#     # create negative \n",
    "#     neg_df = pd.DataFrame()\n",
    "#     cnt = 0 \n",
    "    \n",
    "#     for j in range(len(postal_df)):\n",
    "#         if cnt > 20 :\n",
    "#             break\n",
    "#         if postal_df.postal_code[j] in postal_codes_list and \\\n",
    "#         abs(max_postal - int(postal_df.postal_code[j])) <= 500:\n",
    "#             cnt+=1\n",
    "#             new = pd.DataFrame(tmp.iloc[0]).T.reset_index(drop=True)\n",
    "#             postal_codes_list.remove(postal_df.postal_code[j])\n",
    "#             new = create_new (new ,category, all_df, postal_df)\n",
    "#             neg_df = pd.concat([neg_df ,new ])\n",
    "\n",
    "#     if len(neg_df)<3:\n",
    "#         print(f'Something is wrong with the shape of the neg sample for {i}')\n",
    "#         break\n",
    "    \n",
    "#     # train test split\n",
    "#     tmp_train , tmp_test = train_test_split(tmp, test_size=0.33, shuffle= True,random_state=RANDOM_STATE)\n",
    "#     neg_train , neg_test = train_test_split(neg_df, test_size=0.33, shuffle= True,random_state=RANDOM_STATE)\n",
    "    \n",
    "    \n",
    "#     # merge with neg\n",
    "#     tmp_train = pd.concat([tmp_train,neg_train])\n",
    "#     tmp_test = pd.concat([tmp_test,neg_test])\n",
    "    \n",
    "#     train_df = pd.concat([train_df,tmp_train])\n",
    "#     test_df = pd.concat([test_df,tmp_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df72d58d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:47:47.861727Z",
     "start_time": "2023-04-19T14:46:58.147182Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished constructing....  train res cnt  : 405 test res cnt : 405\n"
     ]
    }
   ],
   "source": [
    "# # POINTWISE v3\n",
    "# 2-4 間分店用方法一取負樣本，其他參照方法二（解決2-4間分店開在非常遙遠的地方）\n",
    "# # split train test \n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "for i in Counter(res_df.name):\n",
    "    \n",
    "    max_postal = max(tmp.postal_code.astype(int))\n",
    "    category = tmp.categories[0]\n",
    "    \n",
    "    tmp = res_df[res_df.name==i].sort_values(['postal_code'],ascending = [False]).reset_index(drop=True)\n",
    "    postal_df = pd.DataFrame(postal_code_feature_dict).T.reset_index().rename(columns={'index': 'postal_code'})\n",
    "    postal_df = postal_df.sort_values(['postal_code'],ascending = [True]).reset_index(drop=True)\n",
    "    postal_codes_list = list(postal_df.postal_code)\n",
    "    \n",
    "    # remove the known postal codes\n",
    "    for postal in Counter(tmp.postal_code):\n",
    "        postal_codes_list.remove(postal)\n",
    "\n",
    "    # merge with location features\n",
    "    tmp = pd.DataFrame(tmp.merge(postal_df, on='postal_code', how='left')).reset_index(drop=True)\n",
    "    \n",
    "    # add competitiveness and review (TO-DO)\n",
    "    tmp['competitiveness']= ''\n",
    "#     tmp['review']= ''\n",
    "    for j in range(len(tmp)):\n",
    "        \n",
    "        # competitiveness\n",
    "        place = all_df[all_df.postal_code == tmp['postal_code'][j]]\n",
    "        tmp['competitiveness'][j] = -(len(Counter(place[place.categories == category].name))/len(Counter(place.name)))\n",
    "        \n",
    "        # TO-DO add review\n",
    "\n",
    "    # 看差距過大的店家\n",
    "    if max(tmp.postal_code.astype(int))- min(tmp.postal_code.astype(int)) > 10000 and len(tmp)<4:\n",
    "\n",
    "        # train test split\n",
    "        tmp_train , tmp_test = train_test_split(tmp, test_size=0.33, shuffle= True,random_state=RANDOM_STATE)\n",
    "        tmp_train = tmp_train.reset_index(drop=True)\n",
    "        tmp_test = tmp_test.reset_index(drop=True)\n",
    "        \n",
    "        ## train \n",
    "        neg_df = pd.DataFrame()\n",
    "\n",
    "        for j in range(len(tmp_train)):\n",
    "\n",
    "            cnt =0 \n",
    "            category = tmp_train.categories[j]\n",
    "\n",
    "            # add the negative samples\n",
    "            for k in range(len(postal_df)):\n",
    "                if cnt<2:\n",
    "                    if postal_df.postal_code[k] in postal_codes_list and\\\n",
    "                    abs(int(postal_df.postal_code[k])- int(tmp_train['postal_code'][j])) <= 1000:\n",
    "                        cnt+=1\n",
    "                        new = pd.DataFrame(tmp_train.iloc[j]).T.reset_index(drop=True)\n",
    "                        postal_codes_list.remove(postal_df.postal_code[k])\n",
    "                        new = create_new (new ,category,postal_df.postal_code[k], all_df, postal_df)\n",
    "                        neg_df = pd.concat([neg_df ,new ])\n",
    "                else:\n",
    "                    break\n",
    "        tmp_train = pd.concat([tmp_train ,neg_df ])\n",
    "\n",
    "        ## test \n",
    "\n",
    "        neg_df = pd.DataFrame()\n",
    "        for j in range(len(tmp_test)):\n",
    "            cnt =0\n",
    "            category = tmp_test.categories[j]\n",
    "\n",
    "            # add negative samples\n",
    "            for k in range(len(postal_df)):\n",
    "                if cnt<2:\n",
    "                    if postal_df.postal_code[k] in postal_codes_list and\\\n",
    "                    abs(int(postal_df.postal_code[k])-int(tmp_test['postal_code'][j])) <= 1000:\n",
    "                        cnt+=1\n",
    "                        new = pd.DataFrame(tmp_test.iloc[j]).T.reset_index(drop=True)\n",
    "                        postal_codes_list.remove(postal_df.postal_code[k])\n",
    "                        new = create_new (new ,category,postal_df.postal_code[k], all_df, postal_df)\n",
    "                        neg_df = pd.concat([neg_df ,new ])\n",
    "                else:\n",
    "                    break\n",
    "        tmp_test = pd.concat([tmp_test ,neg_df ])\n",
    "        \n",
    "    else:\n",
    "        # create negative \n",
    "        neg_df = pd.DataFrame()\n",
    "        cnt = 0 \n",
    "\n",
    "        for j in range(len(postal_df)):\n",
    "            if cnt > 20 :\n",
    "                break\n",
    "            if postal_df.postal_code[j] in postal_codes_list and \\\n",
    "            abs(max_postal - int(postal_df.postal_code[j])) <= 500:\n",
    "                cnt+=1\n",
    "                new = pd.DataFrame(tmp.iloc[0]).T.reset_index(drop=True)\n",
    "                new = new.drop(columns=['density', 'entropy','area_pop', 'accessibility', 'complementary'])\n",
    "                new['postal_code'] = postal_df.postal_code[j]\n",
    "                postal_codes_list.remove(postal_df.postal_code[j])\n",
    "                new = pd.DataFrame(new.merge(postal_df, on='postal_code', how='left'))\n",
    "                new['relevance'] = 0\n",
    "                # add competitiveness\n",
    "                new['competitiveness']=''\n",
    "                place = all_df[all_df.postal_code == postal_df.postal_code[j]].reset_index(drop=True)\n",
    "                new['competitiveness'] = -(len(Counter(place[place.categories ==category].name))/len(Counter(place.name)))\n",
    "\n",
    "                # TO-DO add review \n",
    "                neg_df = pd.concat([neg_df ,new ])\n",
    "\n",
    "\n",
    "        if len(neg_df)<3:\n",
    "            print(f'Something is wrong with the shape of the neg sample for {i}')\n",
    "            break\n",
    "        \n",
    "        # train test split\n",
    "        tmp_train , tmp_test = train_test_split(tmp, test_size=0.33, shuffle= True,random_state=RANDOM_STATE)\n",
    "        neg_train , neg_test = train_test_split(neg_df, test_size=0.33, shuffle= True,random_state=RANDOM_STATE)\n",
    "        # merge with neg\n",
    "        tmp_train = pd.concat([tmp_train,neg_train])\n",
    "        tmp_test = pd.concat([tmp_test,neg_test])\n",
    "\n",
    "    train_df = pd.concat([train_df,tmp_train])\n",
    "    test_df = pd.concat([test_df,tmp_test])\n",
    "print(f'Finished constructing....  train res cnt  : {len(Counter(train_df.name))} test res cnt : {len(Counter(test_df.name))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aaa5037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:49:08.276877Z",
     "start_time": "2023-04-19T14:49:08.271254Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5984, 27), (3160, 27))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape , test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd70dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:49:11.757142Z",
     "start_time": "2023-04-19T14:49:11.657734Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in ['density', 'entropy', 'competitiveness','area_pop', 'accessibility','complementary','relevance']:\n",
    "    train_df[i] = train_df[i].astype('float')\n",
    "    test_df[i] = test_df[i].astype('float')\n",
    "train_df.to_pickle('/home/adam/Steph_C/my_thesis/data/Train_by_postoal_code_without_review_pointwise_v3_3.pkl')\n",
    "test_df.to_pickle('/home/adam/Steph_C/my_thesis/data/Test_by_postoal_code_without_review_pointwise_v3_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33889893",
   "metadata": {},
   "source": [
    "## Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PAIRWISE v1\n",
    "# 每間店 製作多一個正樣本 一個負樣本，兩兩之間不比較\n",
    "# # split train test \n",
    "\n",
    "COLUMN_NAMES = ['res_name','loc_a' ,'loc_b','density',\\\n",
    "                'entropy','area_pop', 'accessibility', \\\n",
    "                'complementary','competitiveness','relevance']\n",
    "\n",
    "train_df = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "test_df = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "for i in Counter(res_df.name):\n",
    "    \n",
    "    max_postal = max(tmp.postal_code.astype(int))\n",
    "    category = tmp.categories[0]\n",
    "    \n",
    "    tmp = res_df[res_df.name==i].sort_values(['postal_code'],ascending = [False]).reset_index(drop=True)\n",
    "    postal_df = pd.DataFrame(postal_code_feature_dict).T.reset_index().rename(columns={'index': 'postal_code'})\n",
    "    postal_df = postal_df.sort_values(['postal_code'],ascending = [True]).reset_index(drop=True)\n",
    "    postal_codes_list = list(postal_df.postal_code)\n",
    "    \n",
    "    # remove the known postal codes\n",
    "    for postal in Counter(tmp.postal_code):\n",
    "        postal_codes_list.remove(postal)\n",
    "\n",
    "    # merge with location features\n",
    "    tmp = pd.DataFrame(tmp.merge(postal_df, on='postal_code', how='left')).reset_index(drop=True)\n",
    "    \n",
    "    # add competitiveness and review (TO-DO)\n",
    "    tmp['competitiveness']= ''\n",
    "#     tmp['review']= ''\n",
    "    for j in range(len(tmp)):\n",
    "        \n",
    "        # competitiveness\n",
    "        place = all_df[all_df.postal_code == tmp['postal_code'][j]]\n",
    "        tmp['competitiveness'][j] = -(len(Counter(place[place.categories == category].name))/len(Counter(place.name)))\n",
    "        \n",
    "        # TO-DO add review\n",
    "\n",
    "    # 看差距過大的店家\n",
    "    if max(tmp.postal_code.astype(int))- min(tmp.postal_code.astype(int)) > 10000 and len(tmp)<4:\n",
    "\n",
    "        # train test split\n",
    "        tmp_train , tmp_test = train_test_split(tmp, test_size=0.33, shuffle= True,random_state=RANDOM_STATE)\n",
    "        tmp_train = tmp_train.reset_index(drop=True)\n",
    "        tmp_test = tmp_test.reset_index(drop=True)\n",
    "        \n",
    "        ## train \n",
    "        neg_df = pd.DataFrame()\n",
    "\n",
    "        for j in range(len(tmp_train)):\n",
    "\n",
    "            cnt =0 \n",
    "            category = tmp_train.categories[j]\n",
    "\n",
    "            # add the negative samples\n",
    "            for k in range(len(postal_df)):\n",
    "                if cnt<2:\n",
    "                    if postal_df.postal_code[k] in postal_codes_list and\\\n",
    "                    abs(int(postal_df.postal_code[k])- int(tmp_train['postal_code'][j])) <= 1000:\n",
    "                        cnt+=1\n",
    "                        new = pd.DataFrame(tmp_train.iloc[j]).T.reset_index(drop=True)\n",
    "                        postal_codes_list.remove(postal_df.postal_code[k])\n",
    "                        new = create_new (new ,category,postal_df.postal_code[k], all_df, postal_df)\n",
    "                        neg_df = pd.concat([neg_df ,new ])\n",
    "                else:\n",
    "                    break\n",
    "        tmp_train = pd.concat([tmp_train ,neg_df ])\n",
    "\n",
    "        ## test \n",
    "\n",
    "        neg_df = pd.DataFrame()\n",
    "        for j in range(len(tmp_test)):\n",
    "            cnt =0\n",
    "            category = tmp_test.categories[j]\n",
    "\n",
    "            # add negative samples\n",
    "            for k in range(len(postal_df)):\n",
    "                if cnt<2:\n",
    "                    if postal_df.postal_code[k] in postal_codes_list and\\\n",
    "                    abs(int(postal_df.postal_code[k])-int(tmp_test['postal_code'][j])) <= 1000:\n",
    "                        cnt+=1\n",
    "                        new = pd.DataFrame(tmp_test.iloc[j]).T.reset_index(drop=True)\n",
    "                        postal_codes_list.remove(postal_df.postal_code[k])\n",
    "                        new = create_new (new ,category,postal_df.postal_code[k], all_df, postal_df)\n",
    "                        neg_df = pd.concat([neg_df ,new ])\n",
    "                else:\n",
    "                    break\n",
    "        tmp_test = pd.concat([tmp_test ,neg_df ])\n",
    "        \n",
    "    else:\n",
    "        # create negative \n",
    "        neg_df = pd.DataFrame()\n",
    "        cnt = 0 \n",
    "\n",
    "        for j in range(len(postal_df)):\n",
    "            if cnt > 20 :\n",
    "                break\n",
    "            if postal_df.postal_code[j] in postal_codes_list and \\\n",
    "            abs(max_postal - int(postal_df.postal_code[j])) <= 500:\n",
    "                cnt+=1\n",
    "                new = pd.DataFrame(tmp.iloc[0]).T.reset_index(drop=True)\n",
    "                new = new.drop(columns=['density', 'entropy','area_pop', 'accessibility', 'complementary'])\n",
    "                new['postal_code'] = postal_df.postal_code[j]\n",
    "                postal_codes_list.remove(postal_df.postal_code[j])\n",
    "                new = pd.DataFrame(new.merge(postal_df, on='postal_code', how='left'))\n",
    "                new['relevance'] = 0\n",
    "                # add competitiveness\n",
    "                new['competitiveness']=''\n",
    "                place = all_df[all_df.postal_code == postal_df.postal_code[j]].reset_index(drop=True)\n",
    "                new['competitiveness'] = -(len(Counter(place[place.categories ==category].name))/len(Counter(place.name)))\n",
    "\n",
    "                # TO-DO add review \n",
    "                neg_df = pd.concat([neg_df ,new ])\n",
    "\n",
    "\n",
    "        if len(neg_df)<3:\n",
    "            print(f'Something is wrong with the shape of the neg sample for {i}')\n",
    "            break\n",
    "        \n",
    "        # train test split\n",
    "        tmp_train , tmp_test = train_test_split(tmp, test_size=0.33, shuffle= True,random_state=RANDOM_STATE)\n",
    "        neg_train , neg_test = train_test_split(neg_df, test_size=0.33, shuffle= True,random_state=RANDOM_STATE)\n",
    "        # merge with neg\n",
    "        tmp_train = pd.concat([tmp_train,neg_train])\n",
    "        tmp_test = pd.concat([tmp_test,neg_test])\n",
    "\n",
    "    train_df = pd.concat([train_df,tmp_train])\n",
    "    test_df = pd.concat([test_df,tmp_test])\n",
    "print(f'Finished constructing....  train res cnt  : {len(Counter(train_df.name))} test res cnt : {len(Counter(test_df.name))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2456c49",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f2edd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.212Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d70afd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.214Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(text : str) -> list:\n",
    "    \n",
    "    tokens = text.lower().rstrip(' ').rstrip('\\n').rstrip('.').split(' ')[:3000]\n",
    "    \n",
    "    p = PorterStemmer()\n",
    "    stemmed_doc =[]\n",
    "    for token in tokens:\n",
    "        stemmed_doc.append(p.stem(token))\n",
    "        \n",
    "    tokens = [i.split(' ') for i in stemmed_doc]\n",
    "    \n",
    "    \n",
    "    final_tokens =[]\n",
    "\n",
    "\n",
    "    for l in tokens:\n",
    "        for word in l:\n",
    "            word = word.rstrip('.').rstrip('\\'').rstrip(',')\n",
    "            if word not in final_tokens and word not in stop_words and len(word)>0:\n",
    "                final_tokens.append(word)\n",
    "    return final_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9d8c4",
   "metadata": {},
   "source": [
    "# Review-based Market Attractiveness Features (MAF)\n",
    "* Turn every restaurant and city to a doc of reviews\n",
    "* Use `dict` to store the dic index of restaurant and city\n",
    "* review - LDA\n",
    "* location - LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64a49e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.217Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_train.postal_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6f6cf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.219Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d646844",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.221Z"
    }
   },
   "outputs": [],
   "source": [
    "# # aspect creation \n",
    "# total_df = pd.concat([df,LDA_df] , ignore_index=True)\n",
    "\n",
    "# docs = []\n",
    "# index =0 \n",
    "\n",
    "\n",
    "# # restaurant\n",
    "# for restaurant in Counter(df.name):\n",
    "#     if index%10 ==0:\n",
    "#         print(f'Now {index} Restaurant ... {restaurant}')\n",
    "#     tmp = df[df.name == restaurant]\n",
    "#     texts = ''.join(tmp.text.tolist())\n",
    "#     docs.append(preprocess(texts))\n",
    "#     indxe +=1\n",
    "\n",
    "# # city \n",
    "# for city_name in Counter(df.city):\n",
    "#     if index%5 ==0:\n",
    "#         print(f'Now {index} City ... {city_name}')\n",
    "#     tmp = total_df[total_df.city == city_name]\n",
    "#     texts = ''.join(tmp.text.tolist())\n",
    "#     docs.append(preprocess(texts))\n",
    "#     index +=1   \n",
    "\n",
    "# # save pickle\n",
    "# with open('./data/docs.pkl', 'wb') as f:\n",
    "#     pickle.dump(docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36965ed",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.223Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/docs.pkl', 'rb') as f:\n",
    "    docs = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40e71f",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b808e75",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.225Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "name_city_dict = {}\n",
    "for restaurant in Counter(df.name):\n",
    "    name_city_dict[restaurant]=index\n",
    "    index +=1\n",
    "    \n",
    "for city_name in Counter(df.city):\n",
    "    name_city_dict[city_name]=index\n",
    "    index +=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b691d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.228Z"
    }
   },
   "outputs": [],
   "source": [
    "### LDA ###\n",
    "common_dictionary = corpora.Dictionary(docs)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in docs]\n",
    "\n",
    "\n",
    "# Train the model on the corpus.\n",
    "lda =  gensim.models.LdaMulticore(corpus = common_corpus, id2word= common_dictionary, num_topics= 10)\n",
    "lda.show_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10dd3e2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.229Z"
    }
   },
   "outputs": [],
   "source": [
    "# check the topic coherence\n",
    "coherence_model_lda = CoherenceModel( model=lda , texts=docs , dictionary=common_dictionary , coherence='c_v' )\n",
    "conherence_lda = coherence_model_lda.get_coherence()\n",
    "print(conherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce41d3e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.233Z"
    }
   },
   "outputs": [],
   "source": [
    "# create restaurant aspects\n",
    "\n",
    "rest_aspect = {}\n",
    "loca_aspect = {}\n",
    "\n",
    "for name in Counter(df.name):\n",
    "    tmp_arr = np.zeros(10)\n",
    "    for i in lda[common_corpus[name_city_dict[name]]]:\n",
    "        tmp_arr[i[0]]=i[1]\n",
    "    rest_aspect[name]= tmp_arr\n",
    "\n",
    "for location in Counter(df.city):\n",
    "    tmp_arr = np.zeros(10)\n",
    "    for i in lda[common_corpus[name_city_dict[location]]]:\n",
    "        tmp_arr[i[0]]=i[1]\n",
    "    loca_aspect[location]= tmp_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c5828",
   "metadata": {},
   "source": [
    "## Affinity & Complementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b1f2cf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.235Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a55c29",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.237Z"
    }
   },
   "outputs": [],
   "source": [
    "df['affinity']=\"\"\n",
    "df['complementary']=\"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df.affinity[i] = rest_aspect[df.name[i]]*loca_aspect[df.city[i]]\n",
    "    df.complementary[i] = rest_aspect[df.name[i]]*(1-loca_aspect[df.city[i]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f428db",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.239Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2777ae",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Review-based Market Competitiveness Feature (MCF)\n",
    "* review - LDA rank "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11e426",
   "metadata": {},
   "source": [
    "# Geographic Features (GeoF)\n",
    "* Density : the restaurant number in the same postal code\n",
    "* Neighbourhood Entropy : entropy measure of the frequency of restaurant categories\n",
    "    * A location with **higher entropy value** is expected to be **more diverse** in terms of restaurant categories,\n",
    "* Competitiveness : the proportion of nearby restaurants with the same type of restaurant \n",
    "* ~~Jensen Quality : Jensen Quality of each venue category as a feature value, rather than simply aggregating Jensen Quality values over all venue categories as a single feature value. ~~\n",
    "* Area popularity : check in counts in the postal code\n",
    "* ~~distance from downtown :~~\n",
    "* Accessibility : transprtation count in the same postal code\n",
    "* Complementary : Possible dual selection (numbers of parking lot and department stores) / All combination of sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff0f46",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.242Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708f513",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.244Z"
    }
   },
   "outputs": [],
   "source": [
    "venue_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ec22e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T14:35:46.246Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataset without review\n",
    "# unhash if neccessary\n",
    "import math\n",
    "\n",
    "# calculate the density by Postal code\n",
    "res_df['density']=\"\"\n",
    "res_df['entropy']=\"\"\n",
    "res_df['competitiveness']=\"\"\n",
    "res_df['area_pop']=\"\"\n",
    "res_df['accessibility']=\"\"\n",
    "res_df['complementary']=\"\"\n",
    "\n",
    "res_cnt = len(Counter(res_df.name))\n",
    "store_cnt = len(Counter(df.name))\n",
    "\n",
    "for i in range(len(res_df)):\n",
    "    \n",
    "    new_place = new_df[new_df.postal_code == res_df.postal_code[i]]\n",
    "    place = res_df[res_df.postal_code == res_df.postal_code[i]]\n",
    "    all_place = df[df.postal_code == res_df.postal_code[i]]\n",
    "    \n",
    "    # density \n",
    "    res_df.density[i] = len(Counter(place.name))\n",
    "    \n",
    "    # entropy\n",
    "    entropy_sum = 0\n",
    "    \n",
    "    for category in Counter(place.categories):\n",
    "        entropy_sum+=(len(Counter(place[place.categories==category].name))/len(Counter(place.name)))\\\n",
    "        *np.log(len(Counter(place[place.categories==category].name))/len(Counter(place.name)))\n",
    "    res_df.entropy[i] = -entropy_sum\n",
    "    \n",
    "    # Competitiveness\n",
    "    comp = -(len(Counter(place[place.categories == res_df.categories[i]].name))/len(Counter(place.name)))\n",
    "    res_df.competitiveness[i]= comp\n",
    "    \n",
    "    # Area Popularity\n",
    "    pop = len(new_place)\n",
    "    res_df.area_pop[i]= pop\n",
    "    \n",
    "    transportation_cnt = 0\n",
    "    dep_cnt = 0\n",
    "    parking_cnt =0\n",
    "    \n",
    "    for index in range(len(all_place)):\n",
    "        if 'Public Transportation' in all_place.categories[i]:\n",
    "            transportation_cnt+=1\n",
    "        if 'Department Stores' in all_place.categories[i]:\n",
    "            dep_cnt+=1\n",
    "        if 'Parking' in all_place.categories[i]:\n",
    "            parking_cnt+=1\n",
    "    \n",
    "    # Accessibility\n",
    "    res_df.accessibility[i]= transportation_cnt\n",
    "\n",
    "    # Complementary\n",
    "    \n",
    "    res_df.complementary[i] = (2*res_cnt*(dep_cnt+parking_cnt) )/(store_cnt*(store_cnt-1)) \n",
    "    \n",
    "    \n",
    "\n",
    "res_df.to_pickle(\"../data/FE_by_postoal_code_without_review.pkl\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15e957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steph-env",
   "language": "python",
   "name": "steph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
