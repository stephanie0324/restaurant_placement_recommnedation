{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "personal-single",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "diagnostic-fence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T07:35:41.420270Z",
     "start_time": "2023-02-12T07:35:40.651576Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "import operator \n",
    "import joblib\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import os\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "environmental-testament",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T07:35:45.937421Z",
     "start_time": "2023-02-12T07:35:45.935589Z"
    }
   },
   "outputs": [],
   "source": [
    "# configs\n",
    "mallet_path = '../Data/Mallet/bin/mallet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-edwards",
   "metadata": {},
   "source": [
    "# Topic Modelling with LDA Mallet\n",
    "* Get the topics from every review\n",
    "* takes the longest time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decreased-inspiration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T14:55:47.076734Z",
     "start_time": "2023-02-07T14:55:41.504998Z"
    }
   },
   "outputs": [],
   "source": [
    "review_df = pd.read_pickle(\"../Data/yelp/review.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35afb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "docs=review_df['text'].apply(word_tokenize)\n",
    "# a mapping between words and their integer ids\n",
    "d= gensim.corpora.Dictionary(docs)\n",
    "# convert docs to vec\n",
    "v = [d.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "typical-zimbabwe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T14:55:47.336560Z",
     "start_time": "2023-02-07T14:55:47.333328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mallet LDA: 8 topics, 3 topic bits, 111 topic mask\n",
      "Data loaded.\n",
      "max tokens: 721\n",
      "total tokens: 42581005\n",
      "<10> LL/token: -9.61409\n",
      "<20> LL/token: -9.51843\n",
      "<30> LL/token: -9.13989\n",
      "<40> LL/token: -8.87335\n",
      "\n",
      "0\t6.25\t. 's room ) ( area people staff clean n't nice hotel parking location lot stay free walk night kids \n",
      "1\t6.25\t. chicken ordered cheese sauce salad delicious good meal menu bread fried flavor dish sweet meat - fresh side ( \n",
      "2\t6.25\t. 's ! n't good place food ) ... ( great service back .. time - 've & : $ \n",
      "3\t6.25\t. 's place n't great beer bar coffee 've ) selection ( good ! time 're 'm staff friendly find \n",
      "4\t6.25\t. n't told '' `` $ work time back car customer called day call business hair asked store job needed \n",
      "5\t6.25\t. n't food order service time table back minutes ? '' `` wait 's place server waitress good asked bad \n",
      "6\t6.25\t. food good ) place ( great 's restaurant n't : menu - lunch service sushi 've * pretty fresh \n",
      "7\t6.25\t! . 's great place n't ) ... ( -- 've love back time friendly 'm amazing good service ? \n",
      "\n",
      "<50> LL/token: -8.66806\n",
      "<60> LL/token: -8.53494\n",
      "<70> LL/token: -8.45327\n",
      "<80> LL/token: -8.40012\n",
      "<90> LL/token: -8.3619\n",
      "\n",
      "0\t6.25\t. room ) ( people area nice 's clean - parking lot hotel location night free day walk staff : \n",
      "1\t6.25\t. ordered cheese sauce chicken delicious salad meal menu bread sandwich - flavor sweet fried meat dish side good ( \n",
      "2\t6.25\t. 's n't ) ( ... good $ 'm ? pizza place 've - : burger .. pretty stars 5 \n",
      "3\t6.25\t. 's place bar beer selection find coffee great 're 've n't store local prices nice 'm items area location \n",
      "4\t6.25\t. n't work time $ told car customer called '' `` back day business call hair care job needed ( \n",
      "5\t6.25\t. n't '' `` time back order service table minutes ? wait asked food night people server ordered hour experience \n",
      "6\t6.25\t. food good place restaurant ) ( lunch menu service eat fresh : sushi pretty nice rice Service 've quality \n",
      "7\t6.25\t! . great place friendly staff love & amazing back service recommend Great ... time -- awesome super wonderful happy \n",
      "\n",
      "<100> LL/token: -8.33296\n",
      "<110> LL/token: -8.30957\n",
      "<120> LL/token: -8.28968\n",
      "<130> LL/token: -8.27235\n",
      "<140> LL/token: -8.25781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18777/2384799203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# LDA mallet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mldamallet\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamallet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../Data/Mallet/reviews_ldamallet.jl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# NOTE \"--keep-sequence-bigrams\" / \"--use-ngrams true\" poorer results + runs out of memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training MALLET LDA with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# NOTE - we are still keeping the wordtopics variable to not break backward compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"COMMAND: %s %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    949\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LDA mallet\n",
    "ldamallet= gensim.models.wrappers.LdaMallet(mallet_path, corpus = v, num_topics = 8, id2word = d)\n",
    "joblib.dump(ldamallet, '../Data/Mallet/reviews_ldamallet.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "ldamallet_disk = joblib.load('../Data/Mallet/reviews_ldamallet.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-command",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T16:06:13.738411Z",
     "start_time": "2023-02-06T15:59:06.273656Z"
    }
   },
   "outputs": [],
   "source": [
    "#map the reviews data to the model, v is the reviews transformed to word vectors by doc2bow\n",
    "m = ldamallet[v[0:len(v)]]\n",
    "\n",
    "#assign topic to each review\n",
    "topic = []\n",
    "for x in m:\n",
    "    #find the topic with the highest proportions\n",
    "    t = max(x, key = operator.itemgetter(1))\n",
    "    topic.append(t[0])\n",
    "    \n",
    "top_10k = pd.Series(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-current",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T16:54:31.625390Z",
     "start_time": "2023-02-06T16:54:31.603196Z"
    }
   },
   "outputs": [],
   "source": [
    "#map topic names to the topic numbers\n",
    "topic_dict = {0:'Atmosphere', 1:'Food', 2:'Service',\n",
    "             3:'Food', 4:'Waiting time', 5:'Food',\n",
    "             6:'Food', 7:'Hospitality'}\n",
    "\n",
    "top_10k = top_10k.map(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-straight",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T16:55:53.110385Z",
     "start_time": "2023-02-06T16:55:51.969411Z"
    }
   },
   "outputs": [],
   "source": [
    "top_10k.to_csv(\"../Data/Mallet/top_10k_mallet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-verification",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "* score the topics from the restaurants\n",
    "* create dataset with only restaurants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-google",
   "metadata": {},
   "source": [
    "## df construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-wells",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T16:08:20.746078Z",
     "start_time": "2023-02-07T16:08:14.949542Z"
    }
   },
   "outputs": [],
   "source": [
    "#load top_10k_mallet.csv with sub topics\n",
    "lda_mallet = pd.read_csv('../Data/Mallet/top_10k_mallet.csv')\n",
    "#load english data'set with around 10k rows\n",
    "review_df = pd.read_pickle(\"../Data/yelp/review.pkl\")  \n",
    "business_df = pd.read_pickle(\"./Data/yelp/business.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-cause",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T16:09:13.961115Z",
     "start_time": "2023-02-07T16:09:13.364751Z"
    }
   },
   "outputs": [],
   "source": [
    "top_10k = review_df.merge(business_df, on='business_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-monster",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T16:09:14.308503Z",
     "start_time": "2023-02-07T16:09:14.296979Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_mallet['Unnamed: 0'] = top_10k.name\n",
    "lda_mallet.rename(columns = {'Unnamed: 0':'name', '0':'topic'}, inplace = True)\n",
    "lda_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-version",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T16:09:16.393568Z",
     "start_time": "2023-02-07T16:09:15.129185Z"
    }
   },
   "outputs": [],
   "source": [
    "# leave only restaurants\n",
    "top_10k = top_10k.dropna()\n",
    "top_10k = top_10k[top_10k['categories'].str.contains(\"Restaurant\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-representation",
   "metadata": {},
   "source": [
    "## Standard Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-stability",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T16:09:23.914609Z",
     "start_time": "2023-02-07T16:09:19.244490Z"
    }
   },
   "outputs": [],
   "source": [
    "#Standard Sentiment Analysis\n",
    "\n",
    "#load pos_lexicon and neg_lexicon for standard sentiment analysis\n",
    "pos_lexicon = './Data/Mallet/positive-words.txt'\n",
    "neg_lexicon = './Data/Mallet/negative-words.txt'\n",
    "\n",
    "#subset the required columns\n",
    "top_10k_standard = top_10k.loc[:, ['name','business_id', 'text']]\n",
    "\n",
    "#split the reviews into texts by space\n",
    "top_10k_standard['text_sep'] = top_10k_standard['text'].map(lambda x:x.split())\n",
    "\n",
    "#create sentiment lexicons\n",
    "def create_dictionary(path):\n",
    " \n",
    "    dictionary = {}\n",
    "    f = open(path, 'r', encoding = \"ISO-8859-1\")\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        dictionary[line] = 1\n",
    "\n",
    "    f.close()\n",
    "    return dictionary\n",
    "    \n",
    "\n",
    "\n",
    "#calculate sentiment score\n",
    "def sentiment_score(dictionary):\n",
    "\n",
    "    score = top_10k_standard['text_sep'].map(lambda row: list(map(lambda x: 1 if x in dictionary else 0, row)))\n",
    "    score_list = []\n",
    "\n",
    "    for row in score:\n",
    "        score_list.append(sum(row))\n",
    "        \n",
    "    score_df = pd.DataFrame(score_list)\n",
    "    return score_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-desperate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T16:09:51.430399Z",
     "start_time": "2023-02-07T16:09:24.271989Z"
    }
   },
   "outputs": [],
   "source": [
    "#create positive and negative lexicons \n",
    "pos_dict = create_dictionary(pos_lexicon)\n",
    "neg_dict = create_dictionary(neg_lexicon)\n",
    "\n",
    "#calculate sentiment score for each review\n",
    "top_10k_standard['pos_score'] = sentiment_score(pos_dict)\n",
    "top_10k_standard['neg_score'] = sentiment_score(neg_dict)\n",
    "\n",
    "#normalize the score to 0-5\n",
    "top_10k_standard['topic_score'] = top_10k_standard['pos_score'] / (top_10k_standard['pos_score'] + abs(top_10k_standard['neg_score']))*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-cliff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T16:09:52.375940Z",
     "start_time": "2023-02-07T16:09:51.780708Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_score_standard(dataset):\n",
    "\n",
    "    reviews_score = dataset['topic_score']\n",
    "    reviews_score = pd.DataFrame(reviews_score)\n",
    "    \n",
    "    #add new columns to lda_mallet to have individual review score\n",
    "    lda_mallet['topic_score'] = reviews_score\n",
    "    top_10k_score = lda_mallet.loc[:, ['name', 'topic', 'topic_score']]\n",
    "    \n",
    "    #calculate the average ratings for each topic\n",
    "    top_10k_score = round(abs((top_10k_score.groupby(['name',  'topic']).sum() /\n",
    "                    (top_10k_score.groupby(['name', 'topic']).count() + 1))), 1)\n",
    "    \n",
    "    pd.set_option('display.max_rows', 100)\n",
    "    return top_10k_score\n",
    "\n",
    "final_score_standard = final_score_standard(top_10k_standard)\n",
    "final_score_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-graduate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-guard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steph-env",
   "language": "python",
   "name": "steph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
