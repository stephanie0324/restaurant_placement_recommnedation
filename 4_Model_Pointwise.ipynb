{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a4c0bd",
   "metadata": {},
   "source": [
    "# Pointwise\n",
    "* predict the relevance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55501c4",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28aa43a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:11.695590Z",
     "start_time": "2023-05-01T14:11:10.232002Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4eb9d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:11.699857Z",
     "start_time": "2023-05-01T14:11:11.697182Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ed385f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:12.957859Z",
     "start_time": "2023-05-01T14:11:11.701846Z"
    }
   },
   "outputs": [],
   "source": [
    "# 導入資料\n",
    "train_df = pd.read_pickle('/home/adam/Steph_C/my_thesis/data/Train_by_postoal_code_pointwise_v3_3_tfidf.pkl')\n",
    "test_df = pd.read_pickle('/home/adam/Steph_C/my_thesis/data/Test_by_postoal_code_pointwise_v3_3_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45a252a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:12.969888Z",
     "start_time": "2023-05-01T14:11:12.958717Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee55fcf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:12.972669Z",
     "start_time": "2023-05-01T14:11:12.970661Z"
    }
   },
   "outputs": [],
   "source": [
    "# # expr. 1 change relevance score to binary\n",
    "# # change_rel_score = lambda df: 1 if df['relevance']>0 else 0\n",
    "# def change_rel_score(df):\n",
    "#     for i in range(len(df)):\n",
    "#         if df.relevance[i] > 0 :\n",
    "#             df.relevance[i]=1\n",
    "#         else:\n",
    "#             pass\n",
    "    \n",
    "#     return df\n",
    "# train_df = change_rel_score(train_df)\n",
    "# test_df = change_rel_score(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2690623c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:12.986274Z",
     "start_time": "2023-05-01T14:11:12.973348Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1 , random_state = RANDOM_STATE).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1 , random_state = RANDOM_STATE).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68ef8bbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:12.991285Z",
     "start_time": "2023-05-01T14:11:12.987085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(train_df.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb74576d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:12.996068Z",
     "start_time": "2023-05-01T14:11:12.991926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5984, 46)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3701b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:13.001160Z",
     "start_time": "2023-05-01T14:11:12.997609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3160, 46)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8860146c",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aac1e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:13.006027Z",
     "start_time": "2023-05-01T14:11:13.001836Z"
    }
   },
   "outputs": [],
   "source": [
    "def _precision(predictions , actuals, k = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the precision at k\n",
    "    \n",
    "    Returns: a list of precisions\n",
    "    \"\"\"\n",
    "    \n",
    "    precisions =[]\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        \n",
    "        prediction = predictions[i]\n",
    "\n",
    "        if  k != None:\n",
    "            prediction =  predictions[i][:k]\n",
    "        \n",
    "        score = 0\n",
    "        for j in prediction:\n",
    "            if j in actuals[i]:\n",
    "                score+=1\n",
    "        if len(prediction) != 0:\n",
    "            precisions.append(score/len(prediction))\n",
    "        else:\n",
    "            precisions.append(0)\n",
    "    return precisions\n",
    "    \n",
    "\n",
    "def _recall(predictions , actuals, k = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the precision at k\n",
    "    \n",
    "    Returns: a list of recalls\n",
    "    \"\"\"\n",
    "    recalls =[]\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        \n",
    "        prediction =  predictions[i]\n",
    "        \n",
    "        if  k != None:\n",
    "            prediction =  predictions[i][:k]\n",
    "        \n",
    "        score = 0\n",
    "        for j in range(len(prediction)):\n",
    "            if prediction[j] in actuals[i]:\n",
    "                score+=1\n",
    "        recalls.append(score/len(actuals[i]))\n",
    "    \n",
    "    return recalls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba757ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:13.012096Z",
     "start_time": "2023-05-01T14:11:13.006801Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_mrr(predictions, actuals):\n",
    "    \"\"\"\n",
    "    Calculate the mean reciprocal rank (MRR) for a set of predictions and actual values.\n",
    "    \n",
    "    Parameters:\n",
    "    predictions (list of lists): A list of predicted rankings sorted by probability.\n",
    "    actual (list of lists): A list of actual rankings sorted by relevance.\n",
    "    \n",
    "    Returns:    \n",
    "    float: A list of MRR scores.\n",
    "    \"\"\"\n",
    "    mrr_list = []\n",
    "    for i in range(len(predictions)):\n",
    "        reciprocal_rank = 0\n",
    "        if actuals[i][0] in predictions[i]:\n",
    "            reciprocal_rank = 1/ (predictions[i].index(actuals[i][0]) + 1)\n",
    "        mrr_list.append(reciprocal_rank)\n",
    "    return mrr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc4a4af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:13.016763Z",
     "start_time": "2023-05-01T14:11:13.013042Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_map( predictions , actuals, k=None):\n",
    "    \"\"\"\n",
    "    Calculate the mean average precision (MAP) for a set of queries.\n",
    "\n",
    "    Parameters:\n",
    "    actual (list of sets or lists): A list of sets or lists of the actual relevant items for each query.\n",
    "    predicted (list of lists): A list of lists of predicted items for each query.\n",
    "    k (int): The maximum number of predicted items to consider for each query.\n",
    "\n",
    "    Returns:\n",
    "    float: A list of MAP scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    map_list = []\n",
    "    \n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        \n",
    "        ap_list = []\n",
    "        hit = 0 \n",
    "        cnt = 0 \n",
    "        \n",
    "        prediction =  predictions[i]\n",
    "        \n",
    "        if k != None:\n",
    "            prediction =  predictions[i][:k]\n",
    "        \n",
    "        \n",
    "        for j in prediction:\n",
    "            if j in actuals[i]:\n",
    "                hit+=1\n",
    "                cnt+=1\n",
    "                ap_list.append(hit/cnt)\n",
    "            else:\n",
    "                cnt+=1\n",
    "        if len(ap_list) != 0:\n",
    "            map_list.append(np.mean(ap_list))\n",
    "        else:\n",
    "            map_list.append(0)\n",
    "    \n",
    "    return map_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51d7ce0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:13.022021Z",
     "start_time": "2023-05-01T14:11:13.017541Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_dcg_ndcg( predictions , actuals, rel ,k=None):\n",
    "    \"\"\"\n",
    "    Calculate the DCG@k , NDCG@k for a set of queries.\n",
    "\n",
    "    Parameters:\n",
    "    actual (list of sets or lists): A list of sets or lists of the actual relevant items for each query.\n",
    "    predicted (list of lists): A list of lists of predicted items for each query.\n",
    "    k (int): The maximum number of predicted items to consider for each query.\n",
    "\n",
    "    Returns:\n",
    "    float: A list of DCG , NDCG scores.\n",
    "    \"\"\"\n",
    "    dcg_list = []\n",
    "    ndcg_list = []\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        dcg =0\n",
    "        idcg =0\n",
    "        \n",
    "        prediction = predictions[i]\n",
    "        \n",
    "        if k != None:\n",
    "            prediction = predictions[i][:k]\n",
    "        \n",
    "        for j in range(len(actuals[i])):\n",
    "            if actuals[i][j] in prediction:\n",
    "                rank = prediction.index(actuals[i][j]) + 1\n",
    "                dcg += np.divide(float(rel[i][j]),np.log2(rank+1))\n",
    "            idcg += np.divide(float(rel[i][j]),np.log2((j+1)+1))\n",
    "        dcg_list.append(dcg)\n",
    "        if np.divide(dcg,idcg) > 1:\n",
    "            print(rel[i], prediction,actuals[i]  )\n",
    "            print(i,dcg,idcg  , 'Wrong !!!')\n",
    "        ndcg_list.append(np.divide(dcg,idcg))\n",
    "        \n",
    "    return dcg_list , ndcg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31df34a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:13.027038Z",
     "start_time": "2023-05-01T14:11:13.022668Z"
    }
   },
   "outputs": [],
   "source": [
    "# create list of list for query ranking\n",
    "def get_ranking(df ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Turn the probability array into a list of lists for calculation.\n",
    "    \n",
    "    Parameters:\n",
    "    df(DataFrame): the test dataframe\n",
    "    \n",
    "    Returns:\n",
    "    prediction (list of lists): A list of predicted rankings for each query.\n",
    "    actual (list of lists): A list of actual rankings for each query.\n",
    "    \"\"\"\n",
    " \n",
    "    pred_list = []\n",
    "    pred_rel = []\n",
    "    true_list = []\n",
    "    \n",
    "    \n",
    "    for res in Counter(df.name):\n",
    "        \n",
    "        tmp = df[df.name == res]\n",
    "        a_sorted = tmp.sort_values(by=['relevance'],ascending=[False])\n",
    "        p_sorted = tmp.sort_values(by=['predictions'],ascending=[False])\n",
    "        p_sorted = p_sorted[p_sorted.predictions>0]\n",
    "\n",
    "        true_list.append(list(a_sorted[a_sorted.relevance!=0].postal_code))\n",
    "        pred_list.append(list(p_sorted.postal_code))\n",
    "        pred_rel.append(list(a_sorted[a_sorted.relevance!=0].relevance))\n",
    "        \n",
    "        \n",
    "        \n",
    "    return pred_list, pred_rel , true_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20b022",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "086ba40f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:13.038259Z",
     "start_time": "2023-05-01T14:11:13.027695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5984 3160\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "LR = LogisticRegression(random_state=RANDOM_STATE)\n",
    "RF = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "DTC = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "KNC = KNeighborsClassifier()\n",
    "SVC = svm.SVC(random_state=RANDOM_STATE)\n",
    "GNB = GaussianNB()\n",
    "LGBM = LGBMRanker(objective=\"lambdarank\",random_state=RANDOM_STATE)\n",
    "\n",
    "# train_features=['density', 'entropy', 'competitiveness','area_pop', 'accessibility','complementary']\n",
    "# train_features=['density', 'entropy', 'competitiveness','area_pop', 'accessibility','complementary','affinity']\n",
    "# train_features=['density', 'entropy', 'competitiveness','area_pop', 'accessibility','cosine_sim']\n",
    "train_features=['density', 'entropy', 'competitiveness','area_pop', 'accessibility','complementary_with_att','affinity_with_att']\n",
    "\n",
    "\n",
    "get_group_size = lambda df: df.reset_index().groupby(\"name\")['name'].count()\n",
    "\n",
    "train_groups = get_group_size(train_df).to_numpy()\n",
    "test_groups = get_group_size(test_df).to_numpy()\n",
    "\n",
    "print(sum(train_groups) , sum(test_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "746d233f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:19.263208Z",
     "start_time": "2023-05-01T14:11:13.039077Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/adam/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/adam/.local/lib/python3.7/site-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/adam/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/adam/.local/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "models = [LR, RF, DTC, KNC, SVC, GNB, LGBM]\n",
    "model_name =['LR', 'RF', 'DTC', 'KNC', 'SVC', 'GNB','LGBMRanker']\n",
    "score_dict = {}\n",
    "\n",
    "for i in range(len(models)):\n",
    "    score_dict[model_name[i]]={}\n",
    "    model = models[i]\n",
    "    # Train\n",
    "    if model_name[i] != 'LGBMRanker':\n",
    "        model.fit(train_df[train_features], train_df[['relevance']])\n",
    "    else:\n",
    "        model.fit(train_df[train_features], train_df[['relevance']], group=train_groups)\n",
    "    \n",
    "    # Predict\n",
    "    predict = model.predict(test_df[train_features])\n",
    "    test_df['predictions'] = predict\n",
    "    pred_list, pred_rel , true_list = get_ranking(test_df)\n",
    "\n",
    "    # Evaluation\n",
    "    mrr_list = calculate_mrr(pred_list , true_list)\n",
    "    map_list = calculate_map(pred_list , true_list)\n",
    "    dcg_list , ndcg_list = calculate_dcg_ndcg(pred_list , true_list,pred_rel)\n",
    "    precision_list_1 = _precision(pred_list , true_list, k=1)\n",
    "    recall_list_1 = _recall(pred_list , true_list,k=1)\n",
    "    precision_list_3 = _precision(pred_list , true_list, k=3)\n",
    "    recall_list_3 = _recall(pred_list , true_list,k=3)\n",
    "    precision_list = _precision(pred_list , true_list)\n",
    "    recall_list = _recall(pred_list , true_list)\n",
    "\n",
    "    score_dict[model_name[i]]['precision @ 1'] = np.mean(precision_list_1)\n",
    "#     score_dict[model_name[i]]['recall @ 1'] = np.mean(recall_list_1)\n",
    "    score_dict[model_name[i]]['precision @ 3 '] = np.mean(precision_list_3)\n",
    "    score_dict[model_name[i]]['recall @ 3'] = np.mean(recall_list_3)\n",
    "    score_dict[model_name[i]]['precision'] = np.mean(precision_list)\n",
    "    score_dict[model_name[i]]['recall'] = np.mean(recall_list)\n",
    "    score_dict[model_name[i]]['mrr'] = np.mean(mrr_list)\n",
    "    score_dict[model_name[i]]['map'] = np.mean(map_list)\n",
    "    score_dict[model_name[i]]['dcg'] = np.mean(dcg_list)\n",
    "    score_dict[model_name[i]]['ndcg'] = np.mean(ndcg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3d87b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03e8a2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:11:19.275017Z",
     "start_time": "2023-05-01T14:11:19.264087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>DTC</th>\n",
       "      <th>KNC</th>\n",
       "      <th>SVC</th>\n",
       "      <th>GNB</th>\n",
       "      <th>LGBMRanker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision @ 1</th>\n",
       "      <td>0.104</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision @ 3</th>\n",
       "      <td>0.104</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall @ 3</th>\n",
       "      <td>0.066</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.104</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.066</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map</th>\n",
       "      <td>0.107</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcg</th>\n",
       "      <td>1.060</td>\n",
       "      <td>8.226</td>\n",
       "      <td>9.673</td>\n",
       "      <td>6.182</td>\n",
       "      <td>0.648</td>\n",
       "      <td>4.476</td>\n",
       "      <td>9.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndcg</th>\n",
       "      <td>0.071</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   LR     RF    DTC    KNC    SVC    GNB  LGBMRanker\n",
       "precision @ 1   0.104  0.491  0.558  0.380  0.067  0.343       0.538\n",
       "precision @ 3   0.104  0.490  0.490  0.389  0.065  0.343       0.464\n",
       "recall @ 3      0.066  0.576  0.680  0.409  0.043  0.275       0.621\n",
       "precision       0.104  0.490  0.459  0.400  0.065  0.346       0.471\n",
       "recall          0.066  0.651  0.792  0.497  0.043  0.307       0.765\n",
       "mrr             0.057  0.444  0.526  0.324  0.036  0.230       0.492\n",
       "map             0.107  0.603  0.674  0.482  0.068  0.380       0.649\n",
       "dcg             1.060  8.226  9.673  6.182  0.648  4.476       9.184\n",
       "ndcg            0.071  0.553  0.662  0.420  0.046  0.293       0.631"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score_dict).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c021c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684770de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steph-env",
   "language": "python",
   "name": "steph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
