{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "velvet-integer",
   "metadata": {},
   "source": [
    "# Pointwise\n",
    "* predict the relevance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-rouge",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "macro-plasma",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:01.923928Z",
     "start_time": "2023-05-12T06:20:59.461256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-z0ie7s64 because the default path (/home/emma/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from Evaluations import evaluation_metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "second-haiti",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:01.929362Z",
     "start_time": "2023-05-12T06:21:01.926505Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-affect",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:02.563332Z",
     "start_time": "2023-05-12T06:21:01.931580Z"
    }
   },
   "outputs": [],
   "source": [
    "# 導入資料\n",
    "train_df = pd.read_pickle('../data/Train_by_postoal_code_pointwise_v3_3.pkl').reset_index(drop=True)\n",
    "test_df = pd.read_pickle('../data/Test_by_postoal_code_pointwise_v3_3.pkl').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc29884",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-poland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:05.002122Z",
     "start_time": "2023-05-12T06:21:02.565120Z"
    }
   },
   "outputs": [],
   "source": [
    "# expr. 1 change relevance score to binary\n",
    "def change_rel_score(df):\n",
    "    df['binary_score'] = ''\n",
    "    for idx, row in df.iterrows():\n",
    "        if row.relevance > 0.0:\n",
    "            df['binary_score'][idx] = 1\n",
    "        else:\n",
    "            df['binary_score'][idx] = 0\n",
    "    return df\n",
    "train_df = change_rel_score(train_df)\n",
    "test_df = change_rel_score(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['binary_score' ,'affinity', 'complementary','cosine_sim']\n",
    "for i in label_list : \n",
    "    train_df[i] = train_df[i].astype('float')\n",
    "    test_df[i] = test_df[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-closing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:05.012091Z",
     "start_time": "2023-05-12T06:21:05.004165Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1 , random_state = RANDOM_STATE)\n",
    "test_df = test_df.sample(frac=1 , random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-parks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:05.156494Z",
     "start_time": "2023-05-12T06:21:05.093378Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-interference",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:05.218632Z",
     "start_time": "2023-05-12T06:21:05.159175Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-roommate",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-journal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:05.574854Z",
     "start_time": "2023-05-12T06:21:05.499728Z"
    }
   },
   "outputs": [],
   "source": [
    "# create list of list for query ranking\n",
    "def get_ranking(df , y_label = 'binary_score'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Turn the probability array into a list of lists for calculation.\n",
    "    \n",
    "    Parameters:\n",
    "    df(DataFrame): the test dataframe\n",
    "    \n",
    "    Returns:\n",
    "    prediction (list of lists): A list of predicted rankings for each query.\n",
    "    actual (list of lists): A list of actual rankings for each query.\n",
    "    \"\"\"\n",
    " \n",
    "    pred_list = []\n",
    "    true_rel = []\n",
    "    true_list = []\n",
    "\n",
    "    output_dict = {}\n",
    "    \n",
    "    \n",
    "    for id in Counter(df.business_id):\n",
    "\n",
    "        output_dict[id] = {}\n",
    "        \n",
    "        tmp = df[df.business_id == id]\n",
    "        a_sorted = tmp.sort_values(by=[y_label],ascending=[False])\n",
    "        p_sorted = tmp.sort_values(by=['predictions'],ascending=[False])\n",
    "        # p_sorted = p_sorted[p_sorted.predictions>0]\n",
    "\n",
    "        true_list.append(list(a_sorted[a_sorted.relevance!=0].postal_code))\n",
    "        pred_list.append(list(p_sorted.postal_code))\n",
    "        true_rel.append(list(a_sorted[a_sorted.relevance!=0].relevance))\n",
    "        \n",
    "        output_dict[id]['predict'] = list(p_sorted.postal_code)\n",
    "        output_dict[id]['true'] = list(a_sorted[a_sorted.relevance!=0].postal_code)\n",
    "        \n",
    "        \n",
    "    return pred_list, true_rel , true_list , output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-charm",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-essex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:05.663608Z",
     "start_time": "2023-05-12T06:21:05.576735Z"
    }
   },
   "outputs": [],
   "source": [
    "# models\n",
    "LR = LogisticRegression(random_state=RANDOM_STATE)\n",
    "RF = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "DTC = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "KNC = KNeighborsClassifier()\n",
    "SVC = svm.SVC(random_state=RANDOM_STATE)\n",
    "GNB = GaussianNB()\n",
    "LGBM = LGBMRanker(objective=\"lambdarank\",random_state=RANDOM_STATE)\n",
    "\n",
    "# train_features=['density', 'entropy', 'competitiveness','area_pop']\n",
    "# train_features=['density', 'entropy', 'competitiveness','area_pop','complementary','affinity']\n",
    "# train_features=['density', 'entropy', 'competitiveness','area_pop', 'accessibility','cosine_sim']\n",
    "train_features=['density', 'entropy', 'competitiveness','area_pop','affinity', 'complementary','cosine_sim']\n",
    "\n",
    "\n",
    "get_group_size = lambda df: df.reset_index().groupby(\"business_id\")['business_id'].count()\n",
    "\n",
    "train_groups = get_group_size(train_df).to_numpy()\n",
    "test_groups = get_group_size(test_df).to_numpy()\n",
    "\n",
    "print(sum(train_groups) , sum(test_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-gnome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:43.406415Z",
     "start_time": "2023-05-12T06:21:05.665345Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [LR, RF, DTC, KNC, SVC, GNB, LGBM]\n",
    "model_name =['LR', 'RF', 'DTC', 'KNC', 'SVC', 'GNB' , 'LGBMRanker'] \n",
    "score_dict = {}\n",
    "\n",
    "for i in range(len(models)):\n",
    "    score_dict[model_name[i]]={}\n",
    "    model = models[i]\n",
    "    # Train\n",
    "    if model_name[i] != 'LGBMRanker':\n",
    "        model.fit(train_df[train_features], train_df[['binary_score']])\n",
    "    else:\n",
    "        model.fit(train_df[train_features], train_df[['relevance']], group=train_groups)\n",
    "    \n",
    "    # Predict\n",
    "    predict = model.predict(test_df[train_features])\n",
    "    test_df['predictions'] = predict\n",
    "    if model_name[i] != 'LGBMRanker':\n",
    "        pred_list, true_rel , true_list , output_dict = get_ranking(test_df)\n",
    "    else:\n",
    "        pred_list, true_rel , true_list , output_dict = get_ranking(test_df,'relevance')\n",
    "        \n",
    "\n",
    "    # Evaluation\n",
    "    mrr_list = evaluation_metrics._mrr(pred_list , true_list)\n",
    "    map_list = evaluation_metrics._map(pred_list , true_list)\n",
    "    dcg_list , ndcg_list = evaluation_metrics._dcg_ndcg(pred_list , true_list,true_rel)\n",
    "    precision_list_1 = evaluation_metrics._precision(pred_list , true_list, k=1)\n",
    "    recall_list_1 = evaluation_metrics._recall(pred_list , true_list,k=1)\n",
    "    precision_list_3 = evaluation_metrics._precision(pred_list , true_list, k=3)\n",
    "    recall_list_3 = evaluation_metrics._recall(pred_list , true_list,k=3)\n",
    "    precision_list =evaluation_metrics. _precision(pred_list , true_list)\n",
    "    recall_list = evaluation_metrics._recall(pred_list , true_list)\n",
    "\n",
    "    score_dict[model_name[i]]['precision @ 1'] = np.mean(precision_list_1)\n",
    "#     score_dict[model_name[i]]['recall @ 1'] = np.mean(recall_list_1)\n",
    "    score_dict[model_name[i]]['precision @ 3 '] = np.mean(precision_list_3)\n",
    "    score_dict[model_name[i]]['recall @ 3'] = np.mean(recall_list_3)\n",
    "    score_dict[model_name[i]]['precision'] = np.mean(precision_list)\n",
    "    score_dict[model_name[i]]['recall'] = np.mean(recall_list)\n",
    "    score_dict[model_name[i]]['mrr'] = np.mean(mrr_list)\n",
    "    score_dict[model_name[i]]['map'] = np.mean(map_list)\n",
    "    score_dict[model_name[i]]['dcg'] = np.mean(dcg_list)\n",
    "    score_dict[model_name[i]]['ndcg'] = np.mean(ndcg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-scope",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:43.432825Z",
     "start_time": "2023-05-12T06:21:43.408272Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(score_dict).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-sharp",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:43.508444Z",
     "start_time": "2023-05-12T06:21:43.434565Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(output_dict).T.to_csv('./output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-cosmetic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:21:43.681417Z",
     "start_time": "2023-05-12T06:21:43.510114Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(output_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-swimming",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f457e4bdb0a834eef26de468bbb8aa330d736c8b7db558705075494c4e15f1a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
