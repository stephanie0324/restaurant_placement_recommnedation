{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8d5b21",
   "metadata": {},
   "source": [
    "# Create the features from Topic Modeling\n",
    "* using by_postal_code dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec941861",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b42150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:33.722463Z",
     "start_time": "2023-05-01T11:10:33.063089Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0857e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:36.267151Z",
     "start_time": "2023-05-01T11:10:36.261144Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba49a623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:38.285164Z",
     "start_time": "2023-05-01T11:10:36.757224Z"
    }
   },
   "outputs": [],
   "source": [
    "# 導入資料\n",
    "train_df = pd.read_pickle('/home/adam/Steph_C/my_thesis/data/Train_by_postoal_code_without_review_pointwise_v3_3.pkl')\n",
    "test_df = pd.read_pickle('/home/adam/Steph_C/my_thesis/data/Test_by_postoal_code_without_review_pointwise_v3_3.pkl')\n",
    "all_df = pd.read_pickle('../Data/yelp/restaurant_only.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265a2dfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:40.805223Z",
     "start_time": "2023-05-01T11:10:40.799812Z"
    }
   },
   "outputs": [],
   "source": [
    "# chang column name\n",
    "train_df.rename(columns = {'complementary':'poi_complementary'}, inplace = True)\n",
    "test_df.rename(columns = {'complementary':'poi_complementary'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782f82c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:41.639433Z",
     "start_time": "2023-05-01T11:10:41.446880Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "all_df = all_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca19685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:42.166024Z",
     "start_time": "2023-05-01T11:10:42.160509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5984, 27) (3160, 27) (2112553, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape , test_df.shape , all_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2456c49",
   "metadata": {},
   "source": [
    "# Create Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "590f2edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:51:29.658123Z",
     "start_time": "2023-05-01T11:51:29.652659Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pyLDAvis.gensim_models\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import matutils\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d170aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:45.819087Z",
     "start_time": "2023-05-01T11:10:45.819078Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXAMPLE \n",
    "#import spacy\n",
    "# from spacy.lang.en.examples import sentences \n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_md\")\n",
    "# doc = nlp(sentences[0])\n",
    "# print(doc.text)\n",
    "# for token in doc:\n",
    "#     print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a35aee00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:48.118562Z",
     "start_time": "2023-05-01T11:10:48.112410Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Our spaCy model:\n",
    "# nlp = spacy.load(\"en_core_web_md\")\n",
    "# # Tags I want to remove from the text\n",
    "# removal= ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']\n",
    "# tokens = []\n",
    "\n",
    "# for summary in nlp.pipe(reports['summary']):\n",
    "#     proj_tok = [token.lemma_.lower() for token in summary \\\n",
    "#                 if token.pos_ not in removal and not token.is_stop and token.is_alpha]\n",
    "#     tokens.append(proj_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d70afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:49.276014Z",
     "start_time": "2023-05-01T11:10:48.525179Z"
    }
   },
   "outputs": [],
   "source": [
    "# stop_words = stopwords.words('english')\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "removal= ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']\n",
    "\n",
    "def preprocess(text : str) -> list:\n",
    "    \n",
    "    for summary in nlp.pipe([text]):\n",
    "        proj_tok = [token.lemma_.lower() for token in summary \\\n",
    "                    if token.pos_ not in removal and not token.is_stop and token.is_alpha]\n",
    "\n",
    "    return proj_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a5545dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:57.511614Z",
     "start_time": "2023-05-01T11:10:57.506044Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_attribute_tokens(df):\n",
    "    \n",
    "    attribute_list = ['Ambience' , 'GoodForMeal' ]\n",
    "    att_list = []\n",
    "    df = df.reset_index(drop= True)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            for k,v in df.attributes[i].items():\n",
    "                if k in attribute_list:\n",
    "                    if isinstance(v,dict):\n",
    "                        for k_1 , v_1 in v.items():\n",
    "                            if v_1:\n",
    "                                att_list.append(k_1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return att_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3271e053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:10:58.104928Z",
     "start_time": "2023-05-01T11:10:58.097091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create tokens\n",
    "def get_tokens(df):\n",
    "    \n",
    "    df['res_tokens'] = ''\n",
    "    df['loc_tokens'] = ''\n",
    "    df['res_tokens_with_att'] = ''\n",
    "    df['loc_tokens_with_att'] = ''\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        res_str = ''\n",
    "        loc_str = ''\n",
    "\n",
    "        res = df[df.name==df.name[i]]\n",
    "        res = res[res.postal_code != df.postal_code[i]]\n",
    "\n",
    "        loc = df[df.postal_code==df.postal_code[i]]\n",
    "        loc = loc[loc.name != df.name[i]]\n",
    "\n",
    "        # get res_string\n",
    "        for j in Counter(res.text):\n",
    "            removed = []\n",
    "            if j not in removed:\n",
    "                res_str+=j+' '\n",
    "                removed.append(j)\n",
    "\n",
    "        # get loc_string\n",
    "        for j in Counter(loc.text):\n",
    "            removed = []\n",
    "            if j not in removed:\n",
    "                loc_str+=j+' '\n",
    "                removed.append(j)\n",
    "        \n",
    "        # get attributes tokens\n",
    "        res_att = get_attribute_tokens(res)\n",
    "        loc_att = get_attribute_tokens(loc)\n",
    "        \n",
    "        orig_list_res = preprocess(res_str)\n",
    "        orig_list_loc = preprocess(loc_str)\n",
    "        \n",
    "        df['res_tokens'][i] = orig_list_res\n",
    "        df['loc_tokens'][i] = orig_list_loc\n",
    "        \n",
    "        df['res_tokens_with_att'][i] = orig_list_res+res_att\n",
    "        df['loc_tokens_with_att'][i] = orig_list_loc+loc_att\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    print(f'Finish building .....')\n",
    "    \n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6638e199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T11:41:51.737705Z",
     "start_time": "2023-05-01T11:10:58.626006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building .....\n",
      "Now progress .... 0\n",
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building .....\n"
     ]
    }
   ],
   "source": [
    "# Takes a LONG time\n",
    "train_df = get_tokens(train_df)\n",
    "test_df = get_tokens(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9d8c4",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14ef8429",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T12:30:20.738719Z",
     "start_time": "2023-05-01T12:30:20.718720Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_LDA(train_df , test_df ,tokens):\n",
    "    \n",
    "    train_df['LDA_'+tokens] = ''\n",
    "    test_df['LDA_'+tokens] = ''\n",
    "    dictionary = Dictionary(train_df[tokens])\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=1000)\n",
    "    \n",
    "    #### doc2Bow\n",
    "    train_corpus = [dictionary.doc2bow(doc) for doc in train_df[tokens]]\n",
    "    test_corpus = [dictionary.doc2bow(doc) for doc in test_df[tokens]]\n",
    "\n",
    "    # building models\n",
    "    lda_model = LdaMulticore(corpus=train_corpus, id2word=dictionary, iterations=50, \\\n",
    "                             num_topics=10, workers = 4, passes=10)\n",
    "    \n",
    "    for i in range(len(train_corpus)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        train_df['LDA_'+tokens][i] = lda_model[train_corpus][i]\n",
    "\n",
    "    print(f'Finish building train .....')\n",
    "    \n",
    "    for i in range(len(test_corpus)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        test_df['LDA_'+tokens][i] = lda_model[test_corpus][i]\n",
    "\n",
    "    print(f'Finish building test .....')\n",
    "    return train_df , test_df , lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a74e221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:32:46.468088Z",
     "start_time": "2023-05-01T13:32:46.459965Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_LDA_tfidf(train_df , test_df,tokens ):\n",
    "    \n",
    "    train_df['LDA_'+tokens+'_tfidf'] = ''\n",
    "    test_df['LDA_'+tokens+'_tfidf'] = ''\n",
    "\n",
    "    vectorizer = TfidfVectorizer(min_df=10, max_df=0.2, max_features=1000)\n",
    "    \n",
    "    #### TF-IDF\n",
    "    train_documents = [' '.join(tokens) for tokens in list(train_df[tokens])]\n",
    "    test_documents = [' '.join(tokens) for tokens in list(test_df[tokens])]\n",
    "\n",
    "    train_corpus = matutils.Sparse2Corpus(vectorizer.fit_transform(train_documents).T)\n",
    "    test_corpus = matutils.Sparse2Corpus(vectorizer.fit_transform(test_documents).T)\n",
    "    \n",
    "    \n",
    "    # building models\n",
    "    id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "    lda_model = LdaMulticore(corpus=train_corpus, id2word=id2word, iterations=50, \\\n",
    "                             num_topics=10, workers = 4, passes=10)\n",
    "    \n",
    "    for i in range(len(train_corpus)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        train_df['LDA_'+tokens+'_tfidf'][i] = lda_model[train_corpus][i]\n",
    "\n",
    "    print(f'Finish building train .....')\n",
    "    \n",
    "    for i in range(len(test_corpus)):\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(f'Now progress .... {i}')\n",
    "        \n",
    "        test_df['LDA_'+tokens+'_tfidf'][i] = lda_model[test_corpus][i]\n",
    "\n",
    "    print(f'Finish building test .....')\n",
    "    return train_df , test_df , lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b610a4b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:32:50.812099Z",
     "start_time": "2023-05-01T13:32:47.261519Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-164:\n",
      "Process ForkPoolWorker-163:\n",
      "Process ForkPoolWorker-161:\n",
      "Process ForkPoolWorker-162:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13042/788829356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mres_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_LDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'res_tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mres_lda_w_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_LDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'res_tokens_with_att'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mloc_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_LDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'loc_tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mloc_lda_w_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_LDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'loc_tokens_with_att'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13042/2781910157.py\u001b[0m in \u001b[0;36mget_LDA\u001b[0;34m(train_df, test_df, tokens)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# building models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     lda_model = LdaMulticore(corpus=train_corpus, id2word=dictionary, iterations=50, \\\n\u001b[0;32m---> 14\u001b[0;31m                              num_topics=10, workers = 4, passes=10)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_updates\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mupdateafter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training LDA model using %i processes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mperwordbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m         logger.info(\n\u001b[1;32m    823\u001b[0m             \u001b[0;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   1085\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bound: at document #%i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m                 \u001b[0mgammad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;31m# Substituting the value of the optimal phi back into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;31m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mphinorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m                 \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogthetad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/adam/.local/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/adam/.local/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/adam/.local/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/adam/.local/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "train_df ,test_df , res_lda = get_LDA(train_df ,test_df , 'res_tokens')\n",
    "train_df ,test_df , res_lda_w_attr = get_LDA(train_df ,test_df , 'res_tokens_with_att')\n",
    "train_df ,test_df , loc_lda = get_LDA(train_df ,test_df , 'loc_tokens')\n",
    "train_df ,test_df , loc_lda_w_attr = get_LDA(train_df ,test_df , 'loc_tokens_with_att')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "75cdc859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:33:51.392039Z",
     "start_time": "2023-05-01T13:32:52.941175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building train .....\n",
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building test .....\n",
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Now progress .... 4000\n",
      "Now progress .... 5000\n",
      "Finish building train .....\n",
      "Now progress .... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now progress .... 1000\n",
      "Now progress .... 2000\n",
      "Now progress .... 3000\n",
      "Finish building test .....\n"
     ]
    }
   ],
   "source": [
    "train_df ,test_df , res_lda_tfidf = get_LDA_tfidf(train_df ,test_df , 'res_tokens_with_att')\n",
    "train_df ,test_df , loc_lda_tfidf = get_LDA_tfidf(train_df ,test_df , 'loc_tokens_with_att')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f27b1013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:36:31.786702Z",
     "start_time": "2023-05-01T13:36:31.774486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"plan\" + 0.006*\"enjoy\" + 0.006*\"dave\" + 0.006*\"sorry\" + 0.006*\"inch\" + 0.006*\"saturday\" + 0.005*\"veggie\" + 0.005*\"smoothie\" + 0.005*\"perfection\" + 0.005*\"job\"'),\n",
       " (1,\n",
       "  '0.014*\"card\" + 0.009*\"carmel\" + 0.008*\"noodle\" + 0.007*\"sample\" + 0.007*\"ham\" + 0.006*\"min\" + 0.006*\"coffee\" + 0.005*\"overall\" + 0.005*\"mac\" + 0.005*\"taco\"'),\n",
       " (2,\n",
       "  '0.029*\"plan\" + 0.007*\"saturday\" + 0.006*\"calzone\" + 0.006*\"boil\" + 0.006*\"bun\" + 0.006*\"original\" + 0.006*\"setup\" + 0.006*\"certain\" + 0.005*\"high\" + 0.005*\"bell\"'),\n",
       " (3,\n",
       "  '0.018*\"taco\" + 0.010*\"right\" + 0.009*\"head\" + 0.009*\"believe\" + 0.007*\"card\" + 0.007*\"plain\" + 0.006*\"pub\" + 0.006*\"flag\" + 0.006*\"positive\" + 0.006*\"question\"'),\n",
       " (4,\n",
       "  '0.009*\"positive\" + 0.008*\"min\" + 0.007*\"carmel\" + 0.007*\"set\" + 0.006*\"shut\" + 0.006*\"tonight\" + 0.006*\"taco\" + 0.006*\"plan\" + 0.006*\"lemonade\" + 0.005*\"garage\"'),\n",
       " (5,\n",
       "  '0.014*\"will\" + 0.011*\"plan\" + 0.011*\"bun\" + 0.010*\"bathroom\" + 0.008*\"example\" + 0.006*\"version\" + 0.006*\"market\" + 0.006*\"crazy\" + 0.006*\"consider\" + 0.005*\"saturday\"'),\n",
       " (6,\n",
       "  '0.012*\"steak\" + 0.010*\"veggie\" + 0.009*\"min\" + 0.008*\"bun\" + 0.007*\"awesome\" + 0.007*\"potato\" + 0.007*\"chop\" + 0.006*\"crazy\" + 0.006*\"setup\" + 0.006*\"level\"'),\n",
       " (7,\n",
       "  '0.017*\"club\" + 0.016*\"sushi\" + 0.015*\"ruin\" + 0.010*\"road\" + 0.008*\"fair\" + 0.008*\"big\" + 0.007*\"rating\" + 0.007*\"space\" + 0.006*\"sweet\" + 0.006*\"customer\"'),\n",
       " (8,\n",
       "  '0.035*\"plan\" + 0.007*\"saturday\" + 0.007*\"young\" + 0.007*\"space\" + 0.006*\"encounter\" + 0.006*\"patio\" + 0.006*\"need\" + 0.005*\"level\" + 0.005*\"brisket\" + 0.004*\"bartender\"'),\n",
       " (9,\n",
       "  '0.010*\"plan\" + 0.008*\"dog\" + 0.007*\"example\" + 0.007*\"weekend\" + 0.006*\"dish\" + 0.006*\"starbucks\" + 0.006*\"customer\" + 0.006*\"face\" + 0.005*\"management\" + 0.005*\"market\"')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_lda_tfidf.print_topics(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a09595ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T13:36:34.746630Z",
     "start_time": "2023-05-01T13:36:34.734229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.027*\"popular\" + 0.027*\"tempeh\" + 0.019*\"earn\" + 0.019*\"chorizo\" + 0.019*\"limit\" + 0.019*\"whiskey\" + 0.019*\"trimming\" + 0.019*\"mojos\" + 0.018*\"shade\" + 0.018*\"catch\"'),\n",
       " (1,\n",
       "  '0.022*\"bj\" + 0.018*\"flour\" + 0.017*\"imho\" + 0.017*\"bowls\" + 0.016*\"eatery\" + 0.016*\"baked\" + 0.016*\"super\" + 0.014*\"photo\" + 0.013*\"chile\" + 0.013*\"value\"'),\n",
       " (2,\n",
       "  '0.015*\"gallo\" + 0.014*\"heirloom\" + 0.013*\"skeptical\" + 0.008*\"bf\" + 0.008*\"opportunity\" + 0.008*\"robbie\" + 0.008*\"anytime\" + 0.008*\"ladt\" + 0.007*\"peeve\" + 0.007*\"single\"'),\n",
       " (3,\n",
       "  '0.029*\"satisfied\" + 0.022*\"golden\" + 0.019*\"sweeten\" + 0.018*\"brew\" + 0.017*\"celiac\" + 0.017*\"spacious\" + 0.014*\"naan\" + 0.013*\"santucci\" + 0.013*\"current\" + 0.013*\"raspberry\"'),\n",
       " (4,\n",
       "  '0.049*\"samosa\" + 0.049*\"wear\" + 0.046*\"dark\" + 0.025*\"route\" + 0.025*\"credit\" + 0.021*\"ny\" + 0.019*\"ball\" + 0.019*\"movie\" + 0.016*\"focus\" + 0.016*\"cater\"'),\n",
       " (5,\n",
       "  '0.022*\"flatbread\" + 0.021*\"gnocchi\" + 0.017*\"elevate\" + 0.015*\"favs\" + 0.014*\"pound\" + 0.014*\"company\" + 0.014*\"bday\" + 0.013*\"coating\" + 0.012*\"mood\" + 0.012*\"berry\"'),\n",
       " (6,\n",
       "  '0.021*\"milpas\" + 0.016*\"restroom\" + 0.013*\"burn\" + 0.012*\"rage\" + 0.011*\"buffalo\" + 0.011*\"remain\" + 0.011*\"lukewarm\" + 0.011*\"gooey\" + 0.011*\"roma\" + 0.011*\"busboy\"'),\n",
       " (7,\n",
       "  '0.067*\"pricy\" + 0.040*\"masala\" + 0.033*\"desert\" + 0.032*\"lmao\" + 0.026*\"admit\" + 0.024*\"assumption\" + 0.023*\"car\" + 0.021*\"inferior\" + 0.017*\"flatbread\" + 0.015*\"oil\"'),\n",
       " (8,\n",
       "  '0.011*\"count\" + 0.010*\"upper\" + 0.010*\"outdo\" + 0.008*\"chia\" + 0.008*\"clock\" + 0.008*\"sliver\" + 0.008*\"plain\" + 0.008*\"cuss\" + 0.008*\"renee\" + 0.008*\"shiny\"'),\n",
       " (9,\n",
       "  '0.014*\"prove\" + 0.014*\"system\" + 0.013*\"square\" + 0.011*\"torchy\" + 0.010*\"correct\" + 0.010*\"chop\" + 0.007*\"scoop\" + 0.007*\"gem\" + 0.007*\"carnita\" + 0.007*\"blueberry\"')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_lda_tfidf.print_topics(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a6c148",
   "metadata": {},
   "source": [
    "## Cal Cosine Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d9e7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T07:56:52.512806Z",
     "start_time": "2023-05-01T07:56:52.512781Z"
    }
   },
   "outputs": [],
   "source": [
    "# from gensim.matutils import cossim\n",
    "# # Return cosine similarity between two sparse vectors. \n",
    "# # The similarity is a number between <-1.0, 1.0>, higher is more similar.\n",
    "# print(cossim(train_df.LDA_res_tokens[1], train_df.LDA_loc_tokens[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ff2773ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:03:20.089406Z",
     "start_time": "2023-05-01T14:03:20.083325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'stars_x', 'useful', 'funny', 'cool', 'text', 'date',\n",
       "       'name', 'address', 'city', 'state', 'postal_code', 'latitude',\n",
       "       'longitude', 'stars_y', 'review_count', 'is_open', 'attributes',\n",
       "       'categories', 'hours', 'relevance', 'density', 'entropy', 'area_pop',\n",
       "       'accessibility', 'poi_complementary', 'competitiveness', 'res_tokens',\n",
       "       'loc_tokens', 'res_tokens_with_att', 'loc_tokens_with_att',\n",
       "       'LDA_res_tokens', 'LDA_res_tokens_with_att', 'LDA_loc_tokens',\n",
       "       'LDA_loc_tokens_with_att', 'LDA_res_tokens_with_att_tfidf',\n",
       "       'LDA_loc_tokens_with_att_tfidf', 'cosine_sim', 'cosine_sim_w_attr',\n",
       "       'cosine_sim_tfidf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "86c61854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:03:58.295837Z",
     "start_time": "2023-05-01T14:03:58.290320Z"
    }
   },
   "outputs": [],
   "source": [
    "# create Affinity and Complementary\n",
    "from gensim.matutils import cossim\n",
    "\n",
    "def get_cos_sim(df):\n",
    "    \n",
    "    df['cosine_sim'] =''\n",
    "    df['cosine_sim_w_attr'] =''\n",
    "    df['cosine_sim_tfidf'] =''\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        df['cosine_sim'][i] = cossim(df.LDA_res_tokens[i], df.LDA_loc_tokens[i])\n",
    "        df['cosine_sim_w_attr'][i] = cossim(df.LDA_res_tokens_with_att[i], df.LDA_loc_tokens_with_att[i])\n",
    "        df['cosine_sim_tfidf'][i] = cossim(df.LDA_res_tokens_with_att_tfidf[i], df.LDA_loc_tokens_with_att_tfidf[i])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "970be0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:04:05.761977Z",
     "start_time": "2023-05-01T14:03:59.777417Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "train_df = get_cos_sim(train_df)\n",
    "test_df = get_cos_sim(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c5828",
   "metadata": {},
   "source": [
    "## Affinity & Complementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1bdefb38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:10:07.955853Z",
     "start_time": "2023-05-01T14:10:07.948597Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_aff_comp(df) : \n",
    "    \n",
    "    df['affinity'] = ''\n",
    "    df['complementary'] = ''\n",
    "    df['affinity_with_att'] = ''\n",
    "    df['complementary_with_att'] = ''\n",
    "    df['affinity_tfidf'] = ''\n",
    "    df['complementary_tfidf'] = ''\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        affinity = 0\n",
    "        complementary = 0\n",
    "        affinity_with_att = 0\n",
    "        complementary_with_att = 0\n",
    "        affinity_tfidf = 0\n",
    "        complementary_tfidf = 0\n",
    "        \n",
    "        for j in df.LDA_res_tokens[i]:\n",
    "            for k in df.LDA_loc_tokens[i]: \n",
    "                if j[0] in k:\n",
    "                    affinity += j[1]*k[1]\n",
    "                    complementary += j[1]*(1-k[1])\n",
    "        \n",
    "        \n",
    "        for j in df.LDA_res_tokens_with_att[i]:\n",
    "            for k in df.LDA_loc_tokens_with_att[i]: \n",
    "                if j[0] in k:\n",
    "                    affinity_with_att += j[1]*k[1]\n",
    "                    complementary_with_att += j[1]*(1-k[1]) \n",
    "        \n",
    "        for j in df.LDA_res_tokens_with_att_tfidf[i]:\n",
    "            for k in df.LDA_loc_tokens_with_att_tfidf[i]: \n",
    "                if j[0] in k:\n",
    "                    affinity_tfidf += j[1]*k[1]\n",
    "                    complementary_tfidf += j[1]*(1-k[1]) \n",
    "        \n",
    "        df['affinity'][i] = affinity\n",
    "        df['complementary'][i] = complementary\n",
    "        df['affinity_with_att'][i] = affinity_with_att\n",
    "        df['complementary_with_att'][i] = complementary_with_att\n",
    "        df['affinity_tfidf'][i] = affinity_tfidf\n",
    "        df['complementary_tfidf'][i] = complementary_tfidf\n",
    "        \n",
    "    return df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c8a55c29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:10:22.078791Z",
     "start_time": "2023-05-01T14:10:09.970125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/adam/.local/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train_df = get_aff_comp(train_df)\n",
    "test_df = get_aff_comp(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1706264d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:10:31.215044Z",
     "start_time": "2023-05-01T14:10:31.202575Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in ['affinity','complementary','affinity_with_att','complementary_with_att','cosine_sim','affinity_tfidf','complementary_tfidf']:\n",
    "    train_df[i] = train_df[i].astype('float')\n",
    "    test_df[i] = test_df[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8e15e957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T14:10:39.922194Z",
     "start_time": "2023-05-01T14:10:36.737294Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle('/home/adam/Steph_C/my_thesis/data/Train_by_postoal_code_pointwise_v3_3_tfidf.pkl')\n",
    "test_df.to_pickle('/home/adam/Steph_C/my_thesis/data/Test_by_postoal_code_pointwise_v3_3_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ff4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steph-env",
   "language": "python",
   "name": "steph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
